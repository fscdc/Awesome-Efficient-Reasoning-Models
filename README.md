<div align="center">

  <h2><b> Efficient Reasoning Models: A Survey </b></h2>
  <h4> An overview of research in efficient reasoning models</h4>

</div>


<div align="center">

![](https://img.shields.io/github/stars/fscdc/Awesome-Efficient-Reasoning-Models?color=yellow)
![](https://img.shields.io/github/forks/fscdc/Awesome-Efficient-Reasoning-Models?color=lightblue)
![](https://img.shields.io/github/last-commit/fscdc/Awesome-Efficient-Reasoning-Models?color=green)
![](https://img.shields.io/badge/PRs-Welcome-blue)
<a href="https://arxiv.org/abs/2504.10903" target="_blank"><img src="https://img.shields.io/badge/arXiv-2504.10903-009688.svg" alt="arXiv"></a>

</div>

<div align="center">

**[<a href="https://arxiv.org/abs/2504.10903">arXiv</a>]** **[<a href="https://huggingface.co/papers/2504.10903">HuggingFace</a>]** **[<a href="https://x.com/si_feng32704/status/1912378179718901843">X</a>]**

</div>



This repository is for our paper:

> **[Efficient Reasoning Models: A Survey](https://arxiv.org/abs/2504.10903)** \
> [Sicheng Feng](https://fscdc.github.io/)<sup>1,2</sup>, [Gongfan Fang](https://fangggf.github.io/)<sup>1</sup>, [Xinyin Ma](https://horseee.github.io/)<sup>1</sup>, [Xinchao Wang](https://sites.google.com/site/sitexinchaowang/)<sup>1,*</sup> \
> <sup>1</sup>National University of Singapore, Singapore \
> <sup>2</sup>Nankai University, Tianjin, China \
> <sup>âˆ—</sup>Corresponding author: xinchao@nus.edu.sg

---
>
> ðŸ™‹ Please let us know if you find out a mistake or have any suggestions!
> 
> ðŸŒŸ If you find this resource helpful, please consider to star this repository and cite our [research](#citation)!

<p align="center">
<img src="assets/figure2.svg" width = "95%" alt="" align=center />
</p>


## Updates

- 2025-05-24: ðŸš€ We present a fine-grained visual reasoning benchmark - [ReasonMap](https://fscdc.github.io/Reason-Map/)!
- 2025-05-18: ðŸŽ‰ We open a new section about [efficient multimodal reasoning methods](#efficient-multimodal-reasoning)!
- 2025-05-16: ðŸŽ‰ Two-month milestone! Special thanks to [VainF](https://github.com/VainF), [horseee](https://github.com/horseee), [CHEN1594](https://github.com/CHEN1594), [ZhenyuSun-Walker](https://github.com/ZhenyuSun-Walker), [xianzuwu](https://github.com/xianzuwu)!
- 2025-04-16: ðŸ“ The survey is now available on [arXiv](https://arxiv.org/abs/2504.10903)!
- 2025-04-11: ðŸ“š The full paper list is now available, and our survey is coming soon!
- 2025-03-16: ðŸš€ Efficient Reasoning Repo launched!


## Full list


> **Contributions**
>
> If you want to add your paper or update details like conference info or code URLs, please submit a pull request. You can generate the necessary markdown for each paper by filling out `generate_item.py` and running `python generate_item.py`. We greatly appreciate your contributions. Alternatively, you can email me ([Gmail](fscnkucs@gmail.com)) the links to your paper and code, and I will add your paper to the list as soon as possible.

---
<p align="center">
<img src="assets/taxonomy.png" width = "95%" alt="" align=center />
</p>

### Quick Links
  - [Make Long CoT Short](#Make-Long-CoT-Short)
    - [SFT-based Methods](#SFT-based-Methods)
    - [RL-based Methods](#RL-based-Methods)
    - [Prompt-driven Methods](#Prompt-driven-Methods)
    - [Latent Reasoning](#Latent-Reasoning)
  - [Build SLM with Strong Reasoning Ability](#Build-SLM-with-Strong-Reasoning-Ability)
    - [Distillation](#Distillation)
    - [Quantization and Pruning](#Quantization-and-Pruning)
    - [RL+SLM Methods](#rlslm-methods)
  - [Let Decoding More Efficient](#Let-Decoding-More-Efficient)
    - [Efficient TTS](#Efficient-TTS)
    - [Other Optimal Methods](#Other-Optimal-Methods)
  - [Efficient Multimodal Reasoning](#Efficient-Multimodal-Reasoning)
  - [Evaluation and Benchmarks](#Evaluation-and-Benchmarks)
  - [Background Papers](#Background-Papers)
  - [Competition](#Competition)





### Make Long CoT Short

#### SFT-based Methods
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/horseee/CoT-Valve.svg?style=social&label=Star)](https://github.com/horseee/CoT-Valve)<br>[CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) <br> Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang |<img width="1002" alt="image" src="figures/cot_valve.png"> |[Github](https://github.com/horseee/CoT-Valve) <br> [Paper](https://arxiv.org/abs/2502.09601)|[//]: #03/16
|[Amplify Adjacent Token Differences: Enhancing Long Chain-of-Thought Reasoning with Shift-FFN](https://arxiv.org/abs/2505.17153) <br> Yao Xu, Mingyu Xu, Fangyu Lei, Wangtao Sun, Xiangrong Zeng, Bingning Wang, Guang Liu, Shizhu He, Jun Zhao, Kang Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17153v1/x3.png"> |[Paper](https://arxiv.org/abs/2505.17153)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/YuxuanJiang1/DRP.svg?style=social&label=Star)](https://github.com/YuxuanJiang1/DRP)<br>[DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models](https://arxiv.org/abs/2505.13975) <br> Yuxuan Jiang, Dawei Li, Frank Ferraro |<img width="1002" alt="image" src="https://github.com/YuxuanJiang1/DRP/blob/main/resources/overview.png"> |[Github](https://github.com/YuxuanJiang1/DRP) <br> [Paper](https://arxiv.org/abs/2505.13975)| [//]: #05/26
  |[![Star](https://img.shields.io/github/stars/czg1225/VeriThinker.svg?style=social&label=Star)](https://github.com/czg1225/VeriThinker)<br>[VeriThinker: Learning to Verify Makes Reasoning Model Efficient](https://arxiv.org/pdf/2505.17941) <br> Zigeng Chen, Xinyin Ma, Gongfan Fang, Ruonan Yu, Xinchao Wang |<img width="1002" alt="image" src="figures/verithinker.png"> |[Github](https://github.com/czg1225/VeriThinker) <br> [Paper](https://arxiv.org/pdf/2505.17941)|[//]: #05/23
|[Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning](https://arxiv.org/abs/2505.14582) <br> Shangziqi Zhao, Jiahao Yuan, Guisong Yang, Usman Naseem |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14582v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14582)| [//]: #05/26
|[![Star](https://img.shields.io/github/stars/ZJU-REAL/Self-Braking-Tuning.svg?style=social&label=Star)](https://github.com/ZJU-REAL/Self-Braking-Tuning)<br>[Let LLMs Break Free from Overthinking via Self-Braking Tuning](https://arxiv.org/abs/2505.14604) <br> Haoran Zhao, Yuchen Yan, Yongliang Shen, Haolei Xu, Wenqi Zhang, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14604v2/x1.png"> |[Github](https://github.com/ZJU-REAL/Self-Braking-Tuning) <br> [Paper](https://arxiv.org/abs/2505.14604)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/w-yibo/R1-Compress.svg?style=social&label=Star)](https://github.com/w-yibo/R1-Compress)<br>[R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search](https://arxiv.org/abs/2505.16838) <br> Yibo Wang, Li Shen, Huanjin Yao, Tiansheng Huang, Rui Liu, Naiqiang Tan, Jiaxing Huang, Kai Zhang, Dacheng Tao |<img width="1002" alt="image" src="figures/r1-compress.png"> |[Github](https://github.com/w-yibo/R1-Compress) <br> [Paper](https://arxiv.org/abs/2505.16838)| [//]: #05/24
|[Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought](https://arxiv.org/abs/2505.15431) <br> Hunyuan team |<img width="1002" alt="image" src="figures/hunyuan.png"> |[Paper](https://arxiv.org/abs/2505.15431)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/ZJU-REAL/Self-Braking-Tuning.svg?style=social&label=Star)](https://github.com/ZJU-REAL/Self-Braking-Tuning)<br>[Let LLMs Break Free from Overthinking via Self-Braking Tuning](https://arxiv.org/abs/2505.14604) <br> Haoran Zhao, Yuchen Yan, Yongliang Shen, Haolei Xu, Wenqi Zhang, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14604v1/x2.png"> |[Github](https://github.com/ZJU-REAL/Self-Braking-Tuning) <br> [Paper](https://arxiv.org/abs/2505.14604)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/ZGCA-AI4Edu/LS-Mixture.svg?style=social&label=Star)](https://github.com/ZGCA-AI4Edu/LS-Mixture)<br>[Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2505.03469) <br> Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen |<img width="1002" alt="image" src="figures/mix-sft.png"> |[Github](https://github.com/ZGCA-AI4Edu/LS-Mixture) <br> [Paper](https://arxiv.org/abs/2505.03469)| [//]: #05/17
|[Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949) <br> NVIDIA |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00949v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.00949)| [//]: #05/05
|[![Publish](https://img.shields.io/badge/Conference-AAAI_2025-blue)]()<br>[C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness](https://arxiv.org/abs/2412.11664) <br> Yu Kang, Xianghui Sun, Liangyu Chen, Wei Zou |<img width="1002" alt="image" src="figures/co3t.png"> |[Paper](https://arxiv.org/abs/2412.11664)|[//]: #03/16
|[![Star](https://img.shields.io/github/stars/tengxiaoliu/LM_skip.svg?style=social&label=Star)](https://github.com/tengxiaoliu/LM_skip) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[Can Language Models Learn to Skip Steps?](https://arxiv.org/abs/2411.01855) <br> Tengxiao Liu, Qipeng Guo, Xiangkun Hu, Cheng Jiayang, Yue Zhang, Xipeng Qiu, Zheng Zhang |<img width="1002" alt="image" src="figures/skip_step.png"> |[Github](https://github.com/tengxiaoliu/LM_skip) <br> [Paper](https://arxiv.org/abs/2411.01855)|[//]: #03/16
|[Distilling System 2 into System 1](https://arxiv.org/abs/2407.06023) <br> Ping Yu, Jing Xu, Jason Weston, Ilia Kulikov |<img width="1002" alt="image" src="figures/distill_sys1_sys2.png"> |[Paper](https://arxiv.org/abs/2407.06023)|[//]: #03/16
|[![Star](https://img.shields.io/github/stars/hemingkx/TokenSkip.svg?style=social&label=Star)](https://github.com/hemingkx/TokenSkip)<br>[TokenSkip: Controllable Chain-of-Thought Compression in LLMs](https://arxiv.org/abs/2502.12067) <br> Heming Xia, Yongqi Li, Chak Tou Leong, Wenjie Wang, Wenjie Li |<img width="1002" alt="image" src="figures/TokenSkip.png"> |[Github](https://github.com/hemingkx/TokenSkip) <br> [Paper](https://arxiv.org/abs/2502.12067)|[//]: #03/20
|[Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2502.13260) <br> Yingqian Cui, Pengfei He, Jingying Zeng, Hui Liu, Xianfeng Tang, Zhenwei Dai, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Yue Xing, Jiliang Tang, Qi He |<img width="1002" alt="image" src="https://arxiv.org/html/2502.13260v1/extracted/6214965/pics/merge.png"> |[Paper](https://arxiv.org/abs/2502.13260)| [//]: #04/08
|[Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning](https://arxiv.org/abs/2502.18080) <br> Wenkai Yang, Shuming Ma, Yankai Lin, Furu Wei |<img width="1002" alt="image" src="https://arxiv.org/html/2502.18080v1/x10.png"> |[Paper](https://arxiv.org/abs/2502.18080)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/TergelMunkhbat/concise-reasoning.svg?style=social&label=Star)](https://github.com/TergelMunkhbat/concise-reasoning)<br>[Self-Training Elicits Concise Reasoning in Large Language Models](https://arxiv.org/abs/2502.20122) <br> Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun |<img width="1002" alt="image" src="https://arxiv.org/html/2502.20122v2/x1.png"> |[Github](https://github.com/TergelMunkhbat/concise-reasoning) <br> [Paper](https://arxiv.org/abs/2502.20122)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/GeniusHTX/TALE.svg?style=social&label=Star)](https://github.com/GeniusHTX/TALE)<br>[Token-Budget-Aware LLM Reasoning](https://arxiv.org/abs/2412.18547) <br> Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2412.18547v4/x10.png"> |[Github](https://github.com/GeniusHTX/TALE) <br> [Paper](https://arxiv.org/abs/2412.18547)| [//]: #04/08


#### RL-based Methods
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning](https://arxiv.org/abs/2506.08125) <br> Hanbing Liu, Lang Cao, Yuanyi Ren, Mengyu Zhou, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2506.08125v1/x3.png"> | [Paper](https://arxiv.org/abs/2506.08125)| [//]: #06/09
|[![Star](https://img.shields.io/github/stars/VainF/Thinkless.svg?style=social&label=Star)](https://github.com/VainF/Thinkless)<br>[Thinkless: LLM Learns When to Think](https://arxiv.org/abs/2505.13379) <br> Gongfan Fang, Xinyin Ma, Xinchao Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13379v1/x1.png"> |[Github](https://github.com/VainF/Thinkless) <br> [Paper](https://arxiv.org/abs/2505.13379)| [//]: #05/20
|[When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning](https://arxiv.org/abs/2505.15400) <br> Xiaoyun Zhang, Jingqing Ruan, Xing Ma, Yawen Zhu, Haodong Zhao, Hao Li, Jiansong Chen, Ke Zeng, Xunliang Cai |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15400v1/x3.png"> |[Paper](https://arxiv.org/abs/2505.15400)| [//]: #05/23
|[![Star](https://img.shields.io/github/stars/hkust-nlp/Laser.svg?style=social&label=Star)](https://github.com/hkust-nlp/Laser)<br>[Learn to Reason Efficiently with Adaptive Length-based Reward Shaping](https://arxiv.org/abs/2505.15612) <br> Wei Liu, Ruochen Zhou, Yiyun Deng, Yuzhen Huang, Junteng Liu, Yuntian Deng, Yizhe Zhang, Junxian He |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15612v1/x1.png"> |[Github](https://github.com/hkust-nlp/Laser) <br> [Paper](https://arxiv.org/abs/2505.15612)| [//]: #05/23
|[Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought](https://arxiv.org/abs/2505.15431) <br> Hunyuan team |<img width="1002" alt="image" src="figures/hunyuan.png"> |[Paper](https://arxiv.org/abs/2505.15431)| [//]: #05/22
|[Think Only When You Need with Large Hybrid-Reasoning Models](https://arxiv.org/abs/2505.14631) <br> Lingjie Jiang, Xun Wu, Shaohan Huang, Qingxiu Dong, Zewen Chi, Li Dong, Xingxing Zhang, Tengchao Lv, Lei Cui, Furu Wei |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14631v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14631)| [//]: #05/22
|[Reward Reasoning Model](https://arxiv.org/abs/2505.14674) <br> Jiaxin Guo, Zewen Chi, Li Dong, Qingxiu Dong, Xun Wu, Shaohan Huang, Furu Wei |<img width="1002" alt="image" src="figures/rrm.png"> |[Paper](https://arxiv.org/abs/2505.14674)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/THU-KEG/AdaptThink.svg?style=social&label=Star)](https://github.com/THU-KEG/AdaptThink)<br>[AdaptThink: Reasoning Models Can Learn When to Think](https://arxiv.org/abs/2505.13417) <br> Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13417v1/x1.png"> |[Github](https://github.com/THU-KEG/AdaptThink) <br> [Paper](https://arxiv.org/abs/2505.13417)| [//]: #05/20
|[Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2505.11827) <br> Yansong Ning, Wei Li, Jun Fang, Naiqiang Tan, Hao Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11827v1/extracted/6447996/Figure/fig3.png"> |[Paper](https://arxiv.org/abs/2505.11827)| [//]: #05/20
|[ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving](https://arxiv.org/abs/2505.12717) <br> Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12717v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.12717)| [//]: #05/20
|[AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning](https://arxiv.org/abs/2505.11896) <br> Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11896v1/extracted/6446095/pareto_optimal_boundary_new_data.png"> |[Paper](https://arxiv.org/abs/2505.11896)| [//]: #05/20
|[Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs](https://arxiv.org/abs/2505.10425) <br> Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10425v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.10425)| [//]: #05/18
|[MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing](https://arxiv.org/abs/2505.07984) <br> Aybora Koksal, A. Aydin Alatan |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07984v1/extracted/6432707/figures/sample_sam.png"> |[Paper](https://arxiv.org/abs/2505.07984)| [//]: #05/17
|[Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org/abs/2505.05315) <br> Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong |<img width="1002" alt="image" src="https://arxiv.org/html/2505.05315v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.05315)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/CodeGoat24/UnifiedReward.svg?style=social&label=Star)](https://github.com/CodeGoat24/UnifiedReward)<br>[Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.03318) <br> Yibin Wang, Zhimin Li, Yuhang Zang, Chunyu Wang, Qinglin Lu, Cheng Jin, Jiaqi Wang |<img width="1002" alt="image" src="figures/umrf.png"> |[Github](https://github.com/CodeGoat24/UnifiedReward) <br> [Paper](https://arxiv.org/abs/2505.03318)| [//]: #05/17
|[Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949) <br> NVIDIA |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00949v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.00949)| [//]: #05/05
|[![Star](https://img.shields.io/github/stars/StarDewXXX/AdaR1.svg?style=social&label=Star)](https://github.com/StarDewXXX/AdaR1)<br>[AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization](https://arxiv.org/abs/2504.21659) <br> Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen |<img width="1002" alt="image" src="figures/AdaR1.png"> |[Github](https://github.com/StarDewXXX/AdaR1) <br> [Paper](https://arxiv.org/abs/2504.21659)|[//]: #05/02
|[![Star](https://img.shields.io/github/stars/StarDewXXX/O1-Pruner.svg?style=social&label=Star)](https://github.com/StarDewXXX/O1-Pruner)<br>[O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning](https://arxiv.org/abs/2501.12570) <br> Haotian Luo, Li Shen, Haiying He, Yibo Wang, Shiwei Liu, Wei Li, Naiqiang Tan, Xiaochun Cao, Dacheng Tao |<img width="1002" alt="image" src="figures/o1_pruner.png"> |[Github](https://github.com/StarDewXXX/O1-Pruner) <br> [Paper](https://arxiv.org/abs/2501.12570)|[//]: #03/16
|[Kimi k1.5: Scaling Reinforcement Learning with LLMs](https://arxiv.org/abs/2501.12599) <br> Kimi Team |<img width="1002" alt="image" src="https://arxiv.org/html/2501.12599v2/x3.png"> |[Paper](https://arxiv.org/abs/2501.12599)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/eddycmu/demystify-long-cot.svg?style=social&label=Star)](https://github.com/eddycmu/demystify-long-cot)<br>[Demystifying Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2502.03373) <br> Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, Xiang Yue |<img width="1002" alt="image" src="https://arxiv.org/html/2502.03373v1/x1.png"> |[Github](https://github.com/eddycmu/demystify-long-cot) <br> [Paper](https://arxiv.org/abs/2502.03373)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Zanette-Labs/efficient-reasoning.svg?style=social&label=Star)](https://github.com/Zanette-Labs/efficient-reasoning)<br>[Training Language Models to Reason Efficiently](https://arxiv.org/abs/2502.04463) <br> Daman Arora, Andrea Zanette |<img width="1002" alt="image" src="https://arxiv.org/html/2502.04463v2/x3.png"> |[Github](https://github.com/Zanette-Labs/efficient-reasoning) <br> [Paper](https://arxiv.org/abs/2502.04463)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/cmu-l3/l1.svg?style=social&label=Star)](https://github.com/cmu-l3/l1)<br>[L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning](https://www.arxiv.org/abs/2503.04697) <br> Pranjal Aggarwal, Sean Welleck |<img width="1002" alt="image" src="https://arxiv.org/html/2503.04697v1/x2.png"> |[Github](https://github.com/cmu-l3/l1) <br> [Paper](https://www.arxiv.org/abs/2503.04697)| [//]: #04/08
|[DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models](https://arxiv.org/abs/2503.04472) <br> Yi Shen, Jian Zhang, Jieyun Huang, Shuming Shi, Wenjing Zhang, Jiangze Yan, Ning Wang, Kai Wang, Shiguo Lian |<img width="1002" alt="image" src="https://arxiv.org/html/2503.04472v1/extracted/6254851/DAST.png"> |[Paper](https://arxiv.org/abs/2503.04472)| [//]: #04/08
|[Adaptive Group Policy Optimization: Towards Stable Training and Token-Efficient Reasoning](https://arxiv.org/abs/2503.15952) <br> Chen Li, Nazhou Liu, Kai Yang |<img width="1002" alt="image" src="figures/agpo.png"> |[Paper](https://arxiv.org/abs/2503.15952)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/UCSB-NLP-Chang/ThinkPrune.svg?style=social&label=Star)](https://github.com/UCSB-NLP-Chang/ThinkPrune)<br>[ThinkPrune: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning](https://arxiv.org/abs/2504.01296) <br> Bairu Hou, Yang Zhang, Jiabao Ji, Yujian Liu, Kaizhi Qian, Jacob Andreas, Shiyu Chang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.01296v1/x1.png"> |[Github](https://github.com/UCSB-NLP-Chang/ThinkPrune) <br> [Paper](https://arxiv.org/abs/2504.01296)| [//]: #04/08
|[Think When You Need: Self-Adaptive Chain-of-Thought Learning](https://arxiv.org/abs/2504.03234) <br> Junjie Yang, Ke Lin, Xing Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2504.03234v1/extracted/6335120/alg_illu.png"> |[Paper](https://arxiv.org/abs/2504.03234)| [//]: #04/08



#### Prompt-driven Methods

##### Prompt-guided Efficint Reasoning

| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Revisiting Overthinking in Long Chain-of-Thought from the Perspective of Self-Doubt](https://arxiv.org/abs/2505.23480) <br> Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Dacheng Tao |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23480v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.23480)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/ZJU-REAL/Self-Braking-Tuning.svg?style=social&label=Star)](https://github.com/ZJU-REAL/Self-Braking-Tuning)<br>[Let LLMs Break Free from Overthinking via Self-Braking Tuning](https://arxiv.org/abs/2505.14604) <br> Haoran Zhao, Yuchen Yan, Yongliang Shen, Haolei Xu, Wenqi Zhang, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14604v1/x2.png"> |[Github](https://github.com/ZJU-REAL/Self-Braking-Tuning) <br> [Paper](https://arxiv.org/abs/2505.14604)| [//]: #05/22
|[Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation](https://arxiv.org/abs/2505.03320) <br> Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.03320v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.03320)| [//]: #05/17
|[Time's Up! An Empirical Study of LLM Reasoning Ability Under Output Length Constraint](https://arxiv.org/abs/2504.14350) <br> Yi Sun, Han Wang, Jiaqiang Li, Jiacheng Liu, Xiangyu Li, Hao Wen, Huiwen Zheng, Yan Liang, Yuanchun Li, Yunxin Liu |<img width="1002" alt="image" src="figures/time_up.png"> |[Paper](https://arxiv.org/abs/2504.14350)| [//]: #04/23
|[CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models](https://arxiv.org/abs/2504.13534) <br> Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui |<img width="1002" alt="image" src="https://arxiv.org/html/2504.13534v1/x2.png"> |[Paper](https://arxiv.org/abs/2504.13534)| [//]: #04/21
|[Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models](https://arxiv.org/abs/2504.13626) <br> Yule Liu, Jingyi Zheng, Zhen Sun, Zifan Peng, Wenhan Dong, Zeyang Sha, Shiwen Cui, Weiqiang Wang, Xinlei He |<img width="1002" alt="image" src="figures/thoughtmani.png"> |[Paper](https://arxiv.org/abs/2504.13626)| [//]: #04/21
|[![Star](https://img.shields.io/github/stars/GeniusHTX/TALE.svg?style=social&label=Star)](https://github.com/GeniusHTX/TALE)<br>[Token-Budget-Aware LLM Reasoning](https://arxiv.org/abs/2412.18547) <br> Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2412.18547v4/x10.png"> |[Github](https://github.com/GeniusHTX/TALE) <br> [Paper](https://arxiv.org/abs/2412.18547)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/matthewrenze/jhu-concise-cot.svg?style=social&label=Star)](https://github.com/matthewrenze/jhu-concise-cot) [![Publish](https://img.shields.io/badge/Conference-FLLM_2024-blue)]()<br>[The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models](https://arxiv.org/abs/2401.05618) <br> Matthew Renze, Erhan Guven |<img width="1002" alt="image" src="https://arxiv.org/html/2401.05618v3/x1.png"> |[Github](https://github.com/matthewrenze/jhu-concise-cot) <br> [Paper](https://arxiv.org/abs/2401.05618)| [//]: #04/08
|[Break the Chain: Large Language Models Can be Shortcut Reasoners](https://arxiv.org/abs/2406.06580) <br> Mengru Ding, Hanmeng Liu, Zhizhang Fu, Jian Song, Wenbo Xie, Yue Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2406.06580v1/x1.png"> |[Paper](https://arxiv.org/abs/2406.06580)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/sileix/chain-of-draft.svg?style=social&label=Star)](https://github.com/sileix/chain-of-draft)<br>[Chain of Draft: Thinking Faster by Writing Less](https://arxiv.org/abs/2502.18600) <br> Silei Xu, Wenhao Xie, Lingxiao Zhao, Pengcheng He |<img width="1002" alt="image" src="https://arxiv.org/html/2502.18600v2/extracted/6244873/plot.png"> |[Github](https://github.com/sileix/chain-of-draft) <br> [Paper](https://arxiv.org/abs/2502.18600)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/LightChen233/reasoning-boundary.svg?style=social&label=Star)](https://github.com/LightChen233/reasoning-boundary) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought](https://arxiv.org/abs/2410.05695) <br> Qiguang Chen, Libo Qin, Jiaqi Wang, Jinxuan Zhou, Wanxiang Che |<img width="1002" alt="image" src="https://arxiv.org/html/2410.05695v2/x1.png"> |[Github](https://github.com/LightChen233/reasoning-boundary) <br> [Paper](https://arxiv.org/abs/2410.05695)| [//]: #04/08
|[How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach](https://arxiv.org/abs/2503.01141) <br> Ayeong Lee, Ethan Che, Tianyi Peng |<img src="https://arxiv.org/html/2503.01141v2/extracted/6325669/plot/mmlu-pro-legend.png" width="45%"> <img src="https://arxiv.org/html/2503.01141v2/extracted/6325669/plot/Anthropic/claude-3-5-sonnet-20241022-mmlu-main.png" width="45%"> |[Paper](https://arxiv.org/abs/2503.01141)| [//]: #04/08



##### Prompt Attribute-Aware Reasoning Routing

| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning](https://arxiv.org/abs/2505.15154) <br> Jinghui Lu, Haiyang Yu, Siliang Xu, Shiwei Ran, Guozhi Tang, Siqi Wang, Bin Shan, Teng Fu, Hao Feng, Jingqun Tang, Han Wang, Can Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15154v1/x10.png"> |[Paper](https://arxiv.org/abs/2505.15154)| [//]: #05/26
|[Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers](https://arxiv.org/abs/2505.12601) <br> Yang Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12601v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.12601)| [//]: #05/20
|[How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach](https://arxiv.org/abs/2503.01141) <br> Ayeong Lee, Ethan Che, Tianyi Peng |<img src="https://arxiv.org/html/2503.01141v2/extracted/6325669/plot/mmlu-pro-legend.png" width="45%"> <img src="https://arxiv.org/html/2503.01141v2/extracted/6325669/plot/Anthropic/claude-3-5-sonnet-20241022-mmlu-main.png" width="45%"> |[Paper](https://arxiv.org/abs/2503.01141)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[RouteLLM: Learning to Route LLMs with Preference Data](https://arxiv.org/abs/2406.18665) <br> Isaac Ong, Amjad Almahairi, Vincent Wu, Wei-Lin Chiang, Tianhao Wu, Joseph E. Gonzalez, M Waleed Kadous, Ion Stoica |<img width="1002" alt="image" src="https://arxiv.org/html/2406.18665v4/extracted/6226172/Figs/gsm8k.png"> |[Paper](https://arxiv.org/abs/2406.18665)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/SimonAytes/SoT.svg?style=social&label=Star)](https://github.com/SimonAytes/SoT)<br>[Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching](https://arxiv.org/abs/2503.05179) <br> Simon A. Aytes, Jinheon Baek, Sung Ju Hwang |<img width="1002" alt="image" src="https://arxiv.org/html/2503.05179v1/x1.png"> |[Github](https://github.com/SimonAytes/SoT) <br> [Paper](https://arxiv.org/abs/2503.05179)| [//]: #04/08
|[Learning to Route LLMs with Confidence Tokens](https://arxiv.org/abs/2410.13284) <br> Yu-Neng Chuang, Helen Zhou, Prathusha Kameswara Sarma, Parikshit Gopalan, John Boccio, Sara Bolouki, Xia Hu |<img width="1002" alt="image" src="https://arxiv.org/html/2410.13284v2/x1.png"> |[Paper](https://arxiv.org/abs/2410.13284)| [//]: #04/08
|[Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization](https://arxiv.org/abs/2502.04428) <br> Yu-Neng Chuang, Leisheng Yu, Guanchu Wang, Lizhe Zhang, Zirui Liu, Xuanting Cai, Yang Sui, Vladimir Braverman, Xia Hu |<img width="1002" alt="image" src="https://arxiv.org/html/2502.04428v1/x1.png"> |[Paper](https://arxiv.org/abs/2502.04428)| [//]: #04/08

###### Blog
* [Claude 3.7 Sonnet](https://www.anthropic.com/news/claude-3-7-sonnet). Claude team. [[Paper]](https://www.anthropic.com/news/claude-3-7-sonnet)


#### Latent Reasoning
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought](https://arxiv.org/abs/2505.24181) <br> Guanghao Li,Wenhao Jiang,Mingfeng Chen,Yan Li,Hao Yu,Shuting Dong,Tao Ren,Ming Tang,Chun Yuan |<img width="1002" alt="image" src="https://arxiv.org/html/2505.24181v1/x3.png"> |[Paper](https://arxiv.org/abs/2505.24181)| [//]: #06/11
|[Continuous Chain of Thought Enables Parallel Exploration and Reasoning](https://arxiv.org/abs/2505.23648) <br> Halil Alperen Gozeten,M. Emrullah Ildiz,Xuechen Zhang,Hrayr Harutyunyan,Ankit Singh Rawat,Samet Oymak |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23648v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.23648)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/Rohan-GRH/CoUT.svg?style=social&label=Star)](https://github.com/Rohan-GRH/CoUT)<br>[Efficient Reasoning via Chain of Unconscious Thought](https://arxiv.org/abs/2505.19756) <br> Ruihan Gong, Yue Liu, Wenjie Qu, Mingzhe Du, Yufei He, Yingwei Ma, Yulin Chen, Xiang Liu, Yi Wen, Xinfeng Li, Ruidong Wang, Xinzhong Zhu, Bryan Hooi, Jiaheng Zhang |<img width="1002" alt="image" src="figures/cout.png"> |[Github](https://github.com/Rohan-GRH/CoUT) <br> [Paper](https://arxiv.org/abs/2505.19756)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/EIT-NLP/Awesome-Latent-CoT.svg?style=social&label=Star)](https://github.com/EIT-NLP/Awesome-Latent-CoT)<br>[Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.16782) <br> Xinghao Chen, Anhao Zhao, Heming Xia, Xuan Lu, Hanlin Wang, Yanjun Chen, Wei Zhang, Jian Wang, Wenjie Li, Xiaoyu Shen |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16782v1/x1.png"> |[Github](https://github.com/EIT-NLP/Awesome-Latent-CoT) <br> [Paper](https://arxiv.org/abs/2505.16782)| [//]: #05/24
|[Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains](https://arxiv.org/abs/2505.16552) <br> Wenhui Tan, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Ruihua Song |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16552v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.16552)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/eric-ai-lab/Soft-Thinking.svg?style=social&label=Star)](https://github.com/eric-ai-lab/Soft-Thinking)<br>[Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space](https://arxiv.org/abs/2505.15778) <br> Zhen Zhang, Xuehai He, Weixiang Yan, Ao Shen, Chenyang Zhao, Shuohang Wang, Yelong Shen, Xin Eric Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15778v1/x1.png"> |[Github](https://github.com/eric-ai-lab/Soft-Thinking) <br> [Paper](https://arxiv.org/abs/2505.15778)| [//]: #05/22
|[Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2505.15634) <br> Zihao Li, Xu Wang, Yuzhe Yang, Ziyu Yao, Haoyi Xiong, Mengnan Du |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15634v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.15634)| [//]: #05/22
|[Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space](https://arxiv.org/abs/2505.13308) <br> Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13308v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.13308)| [//]: #05/20
|[Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought](https://arxiv.org/abs/2505.12514) <br> Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, Yuandong Tian |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12514v1/extracted/6451418/figs/input_format.png"> |[Paper](https://arxiv.org/abs/2505.12514)| [//]: #05/20
|[![Star](https://img.shields.io/github/stars/xuyige/SoftCoT.svg?style=social&label=Star)](https://github.com/xuyige/SoftCoT)<br>[SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.11484) <br> Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11484v1/x1.png"> |[Github](https://github.com/xuyige/SoftCoT) <br> [Paper](https://arxiv.org/abs/2505.11484)| [//]: #05/19
|[Beyond Chains of Thought: Benchmarking Latent-Space Reasoning Abilities in Large Language Models](https://arxiv.org/abs/2504.10615) <br> Thilo Hagendorff, Sarah Fabi |<img width="1002" alt="image" src="./figures/BCoT.png"> |[Paper](https://arxiv.org/abs/2504.10615)|[//]: #04/17
|[Distilling System 2 into System 1](https://arxiv.org/abs/2407.06023) <br> Ping Yu, Jing Xu, Jason Weston, Ilia Kulikov |<img width="1002" alt="image" src="figures/distill_sys1_sys2.png"> |[Paper](https://arxiv.org/abs/2407.06023)|[//]: #03/16
|[![Star](https://img.shields.io/github/stars/da03/implicit_chain_of_thought.svg?style=social&label=Star)](https://github.com/da03/implicit_chain_of_thought/)<br>[Implicit Chain of Thought Reasoning via Knowledge Distillation](https://arxiv.org/abs/2311.01460) <br> Yuntian Deng, Kiran Prasad, Roland Fernandez, Paul Smolensky, Vishrav Chaudhary, Stuart Shieber |<img width="1002" alt="image" src="figures/explicit2implicit.png"> |[Github](https://github.com/da03/implicit_chain_of_thought/) <br> [Paper](https://arxiv.org/abs/2311.01460)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/HKUNLP/diffusion-of-thoughts.svg?style=social&label=Star)](https://github.com/HKUNLP/diffusion-of-thoughts) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models](https://arxiv.org/abs/2402.07754) <br> Jiacheng Ye, Shansan Gong, Liheng Chen, Lin Zheng, Jiahui Gao, Han Shi, Chuan Wu, Xin Jiang, Zhenguo Li, Wei Bi, Lingpeng Kong |<img width="1002" alt="image" src="figures/diffusion_thought.png"> |[Github](https://github.com/HKUNLP/diffusion-of-thoughts) <br> [Paper](https://arxiv.org/abs/2402.07754)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/da03/Internalize_CoT_Step_by_Step.svg?style=social&label=Star)](https://github.com/da03/Internalize_CoT_Step_by_Step)<br>[From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step](https://arxiv.org/abs/2405.14838) <br> Yuntian Deng, Yejin Choi, Stuart Shieber |<img width="1002" alt="image" src="https://arxiv.org/html/2405.14838v1/extracted/2405.14838v1/training_illustration.png"> |[Github](https://github.com/da03/Internalize_CoT_Step_by_Step) <br> [Paper](https://arxiv.org/abs/2405.14838)| [//]: #04/08
|[Compressed Chain of Thought: Efficient Reasoning Through Dense Representations](https://arxiv.org/abs/2412.13171) <br> Jeffrey Cheng, Benjamin Van Durme |<img width="1002" alt="image" src="https://arxiv.org/html/2412.13171v1/extracted/6074157/figures/fig1.png"> |[Paper](https://arxiv.org/abs/2412.13171)| [//]: #04/08
|[SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs](https://arxiv.org/abs/2502.12134) <br> Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao |<img width="1002" alt="image" src="https://arxiv.org/html/2502.12134v1/x1.png"> |[Paper](https://arxiv.org/abs/2502.12134)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[Reasoning with Latent Thoughts: On the Power of Looped Transformers](https://arxiv.org/abs/2502.17416) <br> Nikunj Saunshi, Nishanth Dikkala, Zhiyuan Li, Sanjiv Kumar, Sashank J. Reddi |<img width="1002" alt="image" src="https://arxiv.org/html/2502.17416v1/extracted/6229618/Media/looping_illustration2.png"> |[Paper](https://arxiv.org/abs/2502.17416)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/qifanyu/RELAY.svg?style=social&label=Star)](https://github.com/qifanyu/RELAY)<br>[Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning](https://arxiv.org/abs/2502.08482) <br> Qifan Yu, Zhenyu He, Sijie Li, Xun Zhou, Jun Zhang, Jingjing Xu, Di He |<img width="1002" alt="image" src="https://arxiv.org/html/2502.08482v1/x1.png"> |[Github](https://github.com/qifanyu/RELAY) <br> [Paper](https://arxiv.org/abs/2502.08482)| [//]: #04/08
|[CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation](https://arxiv.org/abs/2502.21074) <br> Zhenyi Shen, Hanqi Yan, Linhai Zhang, Zhanghao Hu, Yali Du, Yulan He |<img width="1002" alt="image" src="https://arxiv.org/html/2502.21074v1/extracted/6241542/figures/codi_illustrate12.png"> |[Paper](https://arxiv.org/abs/2502.21074)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/zjunlp/LightThinker.svg?style=social&label=Star)](https://github.com/zjunlp/LightThinker)<br>[LightThinker: Thinking Step-by-Step Compression](https://arxiv.org/abs/2502.15589) <br> Jintian Zhang, Yuqi Zhu, Mengshu Sun, Yujie Luo, Shuofei Qiao, Lun Du, Da Zheng, Huajun Chen, Ningyu Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2502.15589v1/x1.png"> |[Github](https://github.com/zjunlp/LightThinker) <br> [Paper](https://arxiv.org/abs/2502.15589)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/WANGXinyiLinda/planning_tokens.svg?style=social&label=Star)](https://github.com/WANGXinyiLinda/planning_tokens) [![Publish](https://img.shields.io/badge/Conference-COLM_2024-blue)]()<br>[Guiding Language Model Reasoning with Planning Tokens](https://arxiv.org/abs/2310.05707) <br> Xinyi Wang, Lucas Caccia, Oleksiy Ostapenko, Xingdi Yuan, William Yang Wang, Alessandro Sordoni |<img width="1002" alt="image" src="https://arxiv.org/html/2310.05707v4/extracted/5777851/img/overview.png"> |[Github](https://github.com/WANGXinyiLinda/planning_tokens) <br> [Paper](https://arxiv.org/abs/2310.05707)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/JacobPfau/fillerTokens.svg?style=social&label=Star)](https://github.com/JacobPfau/fillerTokens) [![Publish](https://img.shields.io/badge/Conference-COLM_2024-blue)]()<br>[Let's Think Dot by Dot: Hidden Computation in Transformer Language Models](https://arxiv.org/abs/2404.15758) <br> Jacob Pfau, William Merrill, Samuel R. Bowman |<img width="1002" alt="image" src="https://arxiv.org/html/2404.15758v1/extracted/2404.15758v1/figs/scale_len.png"> |[Github](https://github.com/JacobPfau/fillerTokens) <br> [Paper](https://arxiv.org/abs/2404.15758)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/MingyuJ666/Disentangling-Memory-and-Reasoning.svg?style=social&label=Star)](https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning)<br>[Disentangling Memory and Reasoning Ability in Large Language Models](https://arxiv.org/abs/2411.13504) <br> Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2411.13504v2/x1.png"> |[Github](https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning) <br> [Paper](https://arxiv.org/abs/2411.13504)| [//]: #04/08
|[Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning](https://arxiv.org/abs/2502.03275) <br> DiJia Su, Hanlin Zhu, Yingchen Xu, Jiantao Jiao, Yuandong Tian, Qinqing Zheng |<img width="1002" alt="image" src="https://arxiv.org/html/2502.03275v1/x1.png"> |[Paper](https://arxiv.org/abs/2502.03275)| [//]: #04/08
|[Training Large Language Models to Reason in a Continuous Latent Space](https://arxiv.org/abs/2412.06769) <br> Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian |<img width="1002" alt="image" src="https://arxiv.org/html/2412.06769v2/extracted/6060815/figures/figure_1_meta_3.png"> |[Paper](https://arxiv.org/abs/2412.06769)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/shawnricecake/Heima.svg?style=social&label=Star)](https://github.com/shawnricecake/Heima)<br>[Efficient Reasoning with Hidden Thinking](https://arxiv.org/abs/2501.19201) <br> Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, Jiuxiang Gu |<img width="1002" alt="image" src="https://arxiv.org/html/2501.19201v1/x1.png"> |[Github](https://github.com/shawnricecake/Heima) <br> [Paper](https://arxiv.org/abs/2501.19201)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2024-blue)]()<br>[Think before you speak: Training Language Models With Pause Tokens](https://arxiv.org/abs/2310.02226) <br> Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar, Vaishnavh Nagarajan |<img width="1002" alt="image" src="figures/pause_token.png"> |[Paper](https://arxiv.org/abs/2310.02226)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/seal-rg/recurrent-pretraining.svg?style=social&label=Star)](https://github.com/seal-rg/recurrent-pretraining)<br>[Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach](https://arxiv.org/abs/2502.05171) <br> Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Tom Goldstein |<img width="1002" alt="image" src="https://arxiv.org/html/2502.05171v2/x2.png"> |[Github](https://github.com/seal-rg/recurrent-pretraining) <br> [Paper](https://arxiv.org/abs/2502.05171)| [//]: #04/08
|[Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning](https://arxiv.org/abs/2504.10646) <br> Saif Punjwani, Larry Heck |<img width="1002" alt="image" src="https://arxiv.org/html/2504.10646v1/extracted/6355099/cotvswot.png"> |[Paper](https://arxiv.org/abs/2504.10646)|[//]: #04/16


### Build SLM with Strong Reasoning Ability


#### Distillation 
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Skip-Thinking: Chunk-wise Chain-of-Thought Distillation Enable Smaller Language Models to Reason Better and Faster](https://arxiv.org/abs/2505.18642) <br> Xiao Chen, Sihang Zhou, Ke Liang, Xiaoyu Sun, Xinwang Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.18642v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.18642)| [//]: #06/11
|[Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949) <br> NVIDIA |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00949v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.00949)| [//]: #05/05
|[Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math](https://arxiv.org/abs/2504.21233) <br> Haoran Xu, Baolin Peng, Hany Awadalla, Dongdong Chen, Yen-Chun Chen, Mei Gao, Young Jin Kim, Yunsheng Li, Liliang Ren, Yelong Shen, Shuohang Wang, Weijian Xu, Jianfeng Gao, Weizhu Chen |<img width="1002" alt="image" src="figures/phi_4_mini_reasoning.png"> |[Paper](https://arxiv.org/abs/2504.21233)|[//]: #05/02
|[Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318) <br> Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio CÃ©sar Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng |<img width="1002" alt="image" src="figures/phi_4_reasoning.png"> |[Paper](https://arxiv.org/abs/2504.21318)|[//]: #05/02
| [![Publish](https://img.shields.io/badge/Conference-ACL_2023-blue)]()<br>[Teaching Small Language Models to Reason](https://arxiv.org/abs/2212.08410) <br> Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, Aliaksei Severyn |<img width="1002" alt="image" src="figures/slm_kd.png"> |[Paper](https://arxiv.org/abs/2212.08410)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-EMNLP_2024-blue)]()<br>[Mixed Distillation Helps Smaller Language Model Better Reasoning](https://arxiv.org/abs/2312.10730) <br> Chenglin Li, Qianglong Chen, Liangyue Li, Caiyu Wang, Yicheng Li, Zulong Chen, Yin Zhang |<img width="1002" alt="image" src="figures/mix_distillation.png"> |[Paper](https://arxiv.org/abs/2312.10730)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Small-Model-Gap/Small-Model-Learnability-Gap.svg?style=social&label=Star)](https://github.com/Small-Model-Gap/Small-Model-Learnability-Gap)<br>[Small Models Struggle to Learn from Strong Reasoners](https://arxiv.org/abs/2502.12143) <br> Yuetai Li, Xiang Yue, Zhangchen Xu, Fengqing Jiang, Luyao Niu, Bill Yuchen Lin, Bhaskar Ramasubramanian, Radha Poovendran |<img width="1002" alt="image" src="https://arxiv.org/html/2502.12143v2/x1.png"> |[Github](https://github.com/Small-Model-Gap/Small-Model-Learnability-Gap) <br> [Paper](https://arxiv.org/abs/2502.12143)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Yiwei98/TDG.svg?style=social&label=Star)](https://github.com/Yiwei98/TDG) [![Publish](https://img.shields.io/badge/Conference-AAAI_2024-blue)]()<br>[Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data](https://arxiv.org/abs/2312.12832) <br> Yiwei Li, Peiwen Yuan, Shaoxiong Feng, Boyuan Pan, Bin Sun, Xinglin Wang, Heda Wang, Kan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2312.12832v1/x1.png"> |[Github](https://github.com/Yiwei98/TDG) <br> [Paper](https://arxiv.org/abs/2312.12832)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-EMNLP_2024-blue)]()<br>[Teaching Small Language Models Reasoning through Counterfactual Distillation](https://aclanthology.org/2024.emnlp-main.333/) <br> Tao Feng, Yicheng Li, Li Chenglin, Hao Chen, Fei Yu, Yin Zhang |<img width="1002" alt="image" src="figures/counterfactual_distillation.png"> |[Paper](https://aclanthology.org/2024.emnlp-main.333/)| [//]: #04/08
|[Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation](https://arxiv.org/abs/2503.16385) <br> Yijia Luo, Yulin Song, Xingyao Zhang, Jiaheng Liu, Weixun Wang, GengRu Chen, Wenbo Su, Bo Zheng |<img width="1002" alt="image" src="https://arxiv.org/html/2503.16385v1/x3.png"> |[Paper](https://arxiv.org/abs/2503.16385)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/yunx-z/SCORE.svg?style=social&label=Star)](https://github.com/yunx-z/SCORE) [![Publish](https://img.shields.io/badge/Conference-ACL_Findings_2024-blue)]()<br>[Small Language Models Need Strong Verifiers to Self-Correct Reasoning](https://arxiv.org/abs/2404.17140) <br> Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Moontae Lee, Honglak Lee, Lu Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2404.17140v2/x1.png"> |[Github](https://github.com/yunx-z/SCORE) <br> [Paper](https://arxiv.org/abs/2404.17140)| [//]: #04/08
|[Improving Mathematical Reasoning Capabilities of Small Language Models via Feedback-Driven Distillation](https://arxiv.org/abs/2411.14698) <br> Xunyu Zhu, Jian Li, Can Ma, Weiping Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2411.14698v1/x1.png"> |[Paper](https://arxiv.org/abs/2411.14698)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Xnhyacinth/SKIntern.svg?style=social&label=Star)](https://github.com/Xnhyacinth/SKIntern) [![Publish](https://img.shields.io/badge/Conference-COLING_2025-blue)]()<br>[SKIntern : Internalizing Symbolic Knowledge for Distilling Better CoT Capabilities into Small Language Models](https://arxiv.org/abs/2409.13183) <br> Huanxuan Liao, Shizhu He, Yupu Hao, Xiang Li, Yuanzhe Zhang, Jun Zhao, Kang Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2409.13183v2/x1.png"> |[Github](https://github.com/Xnhyacinth/SKIntern) <br> [Paper](https://arxiv.org/abs/2409.13183)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-COLING_2024-blue)]()<br>[Probe then Retrieve and Reason: Distilling Probing and Reasoning Capabilities into Smaller Language Models](https://aclanthology.org/2024.lrec-main.1140.pdf) <br> Yichun Zhao, Shuheng Zhou, Huijia Zhu |<img width="1002" alt="image" src="figures/prr.png"> |[Paper](https://aclanthology.org/2024.lrec-main.1140.pdf)| [//]: #04/08
|[Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners](https://arxiv.org/abs/2502.20339) <br> Daniele Paliotta, Junxiong Wang, Matteo Pagliardini, Kevin Y. Li, Aviv Bick, J. Zico Kolter, Albert Gu, FranÃ§ois Fleuret, Tri Dao |<img width="1002" alt="image" src="https://arxiv.org/html/2502.20339v1/x1.png"> |[Paper](https://arxiv.org/abs/2502.20339)| [//]: #04/08
|[Distilling Reasoning Ability from Large Language Models with Adaptive Thinking](https://arxiv.org/abs/2404.09170) <br> Xiaoshu Chen, Sihang Zhou, Ke Liang, Xinwang Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2404.09170v5/x1.png"> |[Paper](https://arxiv.org/abs/2404.09170)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/EIT-NLP/Distilling-CoT-Reasoning.svg?style=social&label=Star)](https://github.com/EIT-NLP/Distilling-CoT-Reasoning)<br>[Unveiling the Key Factors for Distilling Chain-of-Thought Reasoning](https://arxiv.org/abs/2502.18001) <br> Xinghao Chen, Zhijing Sun, Wenjin Guo, Miaoran Zhang, Yanjun Chen, Yirong Sun, Hui Su, Yijie Pan, Dietrich Klakow, Wenjie Li, Xiaoyu Shen |<img width="1002" alt="image" src="https://arxiv.org/html/2502.18001v1/x1.png"> |[Github](https://github.com/EIT-NLP/Distilling-CoT-Reasoning) <br> [Paper](https://arxiv.org/abs/2502.18001)| [//]: #04/08

#### Quantization and Pruning
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Towards Reasoning Ability of Small Language Models](https://arxiv.org/abs/2502.11569) <br> Gaurav Srivastava, Shuxiang Cao, Xuan Wang |<img width="1002" alt="image" src="figures/slm_reasoning.png"> |[Paper](https://arxiv.org/abs/2502.11569)| [//]: #04/14
|[![Star](https://img.shields.io/github/stars/ruikangliu/Quantized-Reasoning-Models.svg?style=social&label=Star)](https://github.com/ruikangliu/Quantized-Reasoning-Models)<br>[Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models](https://arxiv.org/abs/2504.04823) <br> Ruikang Liu, Yuxuan Sun, Manyi Zhang, Haoli Bai, Xianzhi Yu, Tiezheng Yu, Chun Yuan, Lu Hou |<img width="1002" alt="image" src="figures/quant_hurt.png"> |[Github](https://github.com/ruikangliu/Quantized-Reasoning-Models) <br> [Paper](https://arxiv.org/abs/2504.04823)| [//]: #04/14
|[When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks](https://arxiv.org/abs/2504.02010) <br> Nan Zhang, Yusen Zhang, Prasenjit Mitra, Rui Zhang |<img width="1002" alt="image" src="figures/when_compression.png"> |[Paper](https://arxiv.org/abs/2504.02010)| [//]: #04/14



#### RL+SLM Methods
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949) <br> NVIDIA |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00949v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.00949)| [//]: #05/05
|[Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math](https://arxiv.org/abs/2504.21233) <br> Haoran Xu, Baolin Peng, Hany Awadalla, Dongdong Chen, Yen-Chun Chen, Mei Gao, Young Jin Kim, Yunsheng Li, Liliang Ren, Yelong Shen, Shuohang Wang, Weijian Xu, Jianfeng Gao, Weizhu Chen |<img width="1002" alt="image" src="figures/phi_4_mini_reasoning.png"> |[Paper](https://arxiv.org/abs/2504.21233)|[//]: #05/02
|[Phi-4-reasoning Technical Report](https://arxiv.org/abs/2504.21318) <br> Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio CÃ©sar Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng |<img width="1002" alt="image" src="figures/phi_4_reasoning.png"> |[Paper](https://arxiv.org/abs/2504.21318)|[//]: #05/02
|[![Star](https://img.shields.io/github/stars/shangshang-wang/Tina.svg?style=social&label=Star)](https://github.com/shangshang-wang/Tina)<br>[Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777) <br> Shangshang Wang, Julian Asilis, Ã–mer Faruk AkgÃ¼l, Enes Burak Bilgin, Ollie Liu, Willie Neiswanger |<img width="1002" alt="image" src="https://arxiv.org/html/2504.15777v1/x4.png"> |[Github](https://github.com/shangshang-wang/Tina) <br> [Paper](https://arxiv.org/abs/2504.15777)| [//]: #04/25
|[![Star](https://img.shields.io/github/stars/knoveleng/open-rs.svg?style=social&label=Star)](https://github.com/knoveleng/open-rs)<br>[Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't](https://arxiv.org/abs/2503.16219) <br> Quy-Anh Dang, Chris Ngo |<img src="https://arxiv.org/html/2503.16219v1/extracted/6296504/images/pass1.png" width="45%"> <img src="https://arxiv.org/html/2503.16219v1/extracted/6296504/images/costs.png" width="45%"> |[Github](https://github.com/knoveleng/open-rs) <br> [Paper](https://arxiv.org/abs/2503.16219)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason.svg?style=social&label=Star)](https://github.com/hkust-nlp/simpleRL-reason)<br>[SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild](https://arxiv.org/abs/2503.18892) <br> Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He |<img width="1002" alt="image" src="figures/simplerl_zoo.png"> |[Github](https://github.com/hkust-nlp/simpleRL-reason) <br> [Paper](https://arxiv.org/abs/2503.18892)| [//]: #04/08

###### Repo

* [DeepScaleR](https://github.com/agentica-project/deepscaler). DeepScaleR team. [Webpage](https://agentica-project.com/)



### Let Decoding More Efficient


#### Efficient TTS
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones](https://arxiv.org/abs/2505.21825) <br> Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera |<img width="1002" alt="image" src="https://arxiv.org/html/2505.21825v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.21825)| [//]: #06/11
|[Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning](https://arxiv.org/abs/2505.17813) <br> Michael Hassid, Gabriel Synnaeve, Yossi Adi, Roy Schwartz |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17813v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.17813)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/kaiwenw/value-guided-search.svg?style=social&label=Star)](https://github.com/kaiwenw/value-guided-search)<br>[Value-Guided Search for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.17373) <br> Kaiwen Wang, Jin Peng Zhou, Jonathan Chang, Zhaolin Gao, Nathan Kallus, KiantÃ© Brantley, Wen Sun |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17373v1/x2.png"> |[Github](https://github.com/kaiwenw/value-guided-search) <br> [Paper](https://arxiv.org/abs/2505.17373)| [//]: #06/11
|[Accelerated Test-Time Scaling with Model-Free Speculative Sampling](https://arxiv.org/abs/2506.04708) <br> Woomin Song, Saket Dingliwal, Sai Muralidhar Jayanthi, Bhavana Ganesh, Jinwoo Shin, Aram Galstyan, Sravan Babu Bodapati |<img width="1002" alt="image" src="figures/stand.png"> |[Paper](https://arxiv.org/abs/2506.04708)|[//]: #06/05
|[Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision](https://arxiv.org/abs/2505.14999) <br> Eric Hanchen Jiang, Haozheng Luo, Shengyuan Pang, Xiaomin Li, Zhenting Qi, Hengli Li, Cheng-Fu Yang, Zongyu Lin, Xinfeng Li, Hao Xu, Kai-Wei Chang, Ying Nian Wu |<img width="1002" alt="image" src="figures/eorm.png"> |[Paper](https://arxiv.org/abs/2505.14999)| [//]: #05/22
|[Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling](https://arxiv.org/abs/2505.11730) <br> Hao Mark Chen, Guanxi Lu, Yasuyuki Okoshi, Zhiwen Mo, Masato Motomura, Hongxiang Fan |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11730v1/x5.png"> |[Paper](https://arxiv.org/abs/2505.11730)| [//]: #05/22
|[Reward Reasoning Model](https://arxiv.org/abs/2505.14674) <br> Jiaxin Guo, Zewen Chi, Li Dong, Qingxiu Dong, Xun Wu, Shaohan Huang, Furu Wei |<img width="1002" alt="image" src="figures/rrm.png"> |[Paper](https://arxiv.org/abs/2505.14674)| [//]: #05/22
|[Fractured Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.12992) <br> Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12992v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.12992)| [//]: #05/20
|[Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately](https://arxiv.org/abs/2505.13326) <br> Yuhang Wang, Youhe Jiang, Bin Cui, Fangcheng Fu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13326v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.13326)| [//]: #05/20
|[Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers](https://arxiv.org/abs/2505.04842) <br> Kusha Sareen, Morgane M Moss, Alessandro Sordoni, Rishabh Agarwal, Arian Hosseini |<img width="1002" alt="image" src="figures/valueback.png"> |[Paper](https://arxiv.org/abs/2505.04842)| [//]: #05/19
|[Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods](https://arxiv.org/abs/2504.14047) <br> Junlin Wang, Shang Zhu, Jon Saad-Falcon, Ben Athiwaratkun, Qingyang Wu, Jue Wang, Shuaiwen Leon Song, Ce Zhang, Bhuwan Dhingra, James Zou |<img width="1002" alt="image" src="https://arxiv.org/html/2504.14047v1/x1.png"> |[Paper](https://arxiv.org/abs/2504.14047)| [//]: #04/23
|[![Star](https://img.shields.io/github/stars/IAAR-Shanghai/xVerify.svg?style=social&label=Star)](https://github.com/IAAR-Shanghai/xVerify)<br>[xVerify: Efficient Answer Verifier for Reasoning Model Evaluations](https://arxiv.org/abs/2504.10481) <br> Ding Chen, Qingchen Yu, Pengyuan Wang, Wentao Zhang, Bo Tang, Feiyu Xiong, Xinchi Li, Minchuan Yang, Zhiyu Li |<img width="1002" alt="image" src="https://arxiv.org/html/2504.10481v1/x1.png"> |[Github](https://github.com/IAAR-Shanghai/xVerify) <br> [Paper](https://arxiv.org/abs/2504.10481)| [//]: #04/17
|[![Star](https://img.shields.io/github/stars/Pranjal2041/AdaptiveConsistency.svg?style=social&label=Star)](https://github.com/Pranjal2041/AdaptiveConsistency)<br>[Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs](https://arxiv.org/abs/2305.11860) <br> Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam |<img width="1002" alt="image" src="figures/asc.png"> |[Github](https://github.com/Pranjal2041/AdaptiveConsistency) <br> [Paper](https://arxiv.org/abs/2305.11860)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Yiwei98/ESC.svg?style=social&label=Star)](https://github.com/Yiwei98/ESC) [![Publish](https://img.shields.io/badge/Conference-ICLR_2024-blue)]()<br>[Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning](https://arxiv.org/abs/2401.10480) <br> Yiwei Li, Peiwen Yuan, Shaoxiong Feng, Boyuan Pan, Xinglin Wang, Bin Sun, Heda Wang, Kan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2401.10480v1/x1.png"> |[Github](https://github.com/Yiwei98/ESC) <br> [Paper](https://arxiv.org/abs/2401.10480)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/WangXinglin/DSC.svg?style=social&label=Star)](https://github.com/WangXinglin/DSC) [![Publish](https://img.shields.io/badge/Conference-NAACL_Findings_2025-blue)]()<br>[Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning](https://arxiv.org/abs/2408.13457) <br> Xinglin Wang, Shaoxiong Feng, Yiwei Li, Peiwen Yuan, Yueqi Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2408.13457v3/x3.png"> |[Github](https://github.com/WangXinglin/DSC) <br> [Paper](https://arxiv.org/abs/2408.13457)| [//]: #04/08
|[Path-Consistency: Prefix Enhancement for Efficient Inference in LLM](https://arxiv.org/abs/2409.01281) <br> Jiace Zhu, Yingtao Shen, Jie Zhao, An Zou |<img width="1002" alt="image" src="https://arxiv.org/html/2409.01281v2/x1.png"> |[Paper](https://arxiv.org/abs/2409.01281)| [//]: #04/08
|[Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning](https://arxiv.org/abs/2502.00511) <br> Zhi Zhou, Tan Yuhao, Zenan Li, Yuan Yao, Lan-Zhe Guo, Xiaoxing Ma, Yu-Feng Li |<img width="1002" alt="image" src="https://arxiv.org/html/2502.00511v2/x3.png"> |[Paper](https://arxiv.org/abs/2502.00511)| [//]: #04/08
|[Confidence Improves Self-Consistency in LLMs](https://arxiv.org/abs/2502.06233) <br> Amir Taubenfeld, Tom Sheffer, Eran Ofek, Amir Feder, Ariel Goldstein, Zorik Gekhman, Gal Yona |<img width="1002" alt="image" src="figures/cisc.png"> |[Paper](https://arxiv.org/abs/2502.06233)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Chengsong-Huang/Self-Calibration.svg?style=social&label=Star)](https://github.com/Chengsong-Huang/Self-Calibration)<br>[Efficient Test-Time Scaling via Self-Calibration](https://arxiv.org/abs/2503.00031) <br> Chengsong Huang, Langlin Huang, Jixuan Leng, Jiacheng Liu, Jiaxin Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2503.00031v1/x2.png"> |[Github](https://github.com/Chengsong-Huang/Self-Calibration) <br> [Paper](https://arxiv.org/abs/2503.00031)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Zanette-Labs/SpeculativeRejection.svg?style=social&label=Star)](https://github.com/Zanette-Labs/SpeculativeRejection) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[Fast Best-of-N Decoding via Speculative Rejection](https://arxiv.org/abs/2410.20290) <br> Hanshi Sun, Momin Haider, Ruiqi Zhang, Huitao Yang, Jiahao Qiu, Ming Yin, Mengdi Wang, Peter Bartlett, Andrea Zanette |<img width="1002" alt="image" src="https://arxiv.org/html/2410.20290v2/x1.png"> |[Github](https://github.com/Zanette-Labs/SpeculativeRejection) <br> [Paper](https://arxiv.org/abs/2410.20290)| [//]: #04/08
|[Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding](https://arxiv.org/abs/2503.01422) <br> Yiming Wang, Pei Zhang, Siyuan Huang, Baosong Yang, Zhuosheng Zhang, Fei Huang, Rui Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2503.01422v1/x1.png"> |[Paper](https://arxiv.org/abs/2503.01422)| [//]: #04/08
|[FastMCTS: A Simple Sampling Strategy for Data Synthesis](https://www.arxiv.org/abs/2502.11476) <br> Peiji Li, Kai Lv, Yunfan Shao, Yichuan Ma, Linyang Li, Xiaoqing Zheng, Xipeng Qiu, Qipeng Guo |<img width="1002" alt="image" src="https://arxiv.org/html/2502.11476v1/x2.png"> |[Paper](https://www.arxiv.org/abs/2502.11476)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/chang-github-00/LLM-Predictive-Decoding.svg?style=social&label=Star)](https://github.com/chang-github-00/LLM-Predictive-Decoding) [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[Non-myopic Generation of Language Models for Reasoning and Planning](https://arxiv.org/abs/2410.17195) <br> Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, Lingpeng Kong |<img width="1002" alt="image" src="figures/predictive_decoding.png"> |[Github](https://github.com/chang-github-00/LLM-Predictive-Decoding) <br> [Paper](https://arxiv.org/abs/2410.17195)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/ethanm88/self-taught-lookahead.svg?style=social&label=Star)](https://github.com/ethanm88/self-taught-lookahead)<br>[Language Models can Self-Improve at State-Value Estimation for Better Search](https://arxiv.org/abs/2503.02878) <br> Ethan Mendes, Alan Ritter |<img width="1002" alt="image" src="https://arxiv.org/html/2503.02878v1/x1.png"> |[Github](https://github.com/ethanm88/self-taught-lookahead) <br> [Paper](https://arxiv.org/abs/2503.02878)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/xufangzhi/phi-Decoding.svg?style=social&label=Star)](https://github.com/xufangzhi/phi-Decoding)<br>[Ï•-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation](https://arxiv.org/abs/2503.13288) <br> Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu |<img width="1002" alt="image" src="https://arxiv.org/html/2503.13288v1/x2.png"> |[Github](https://github.com/xufangzhi/phi-Decoding) <br> [Paper](https://arxiv.org/abs/2503.13288)| [//]: #04/08
|[Dynamic Parallel Tree Search for Efficient LLM Reasoning](https://arxiv.org/abs/2502.16235) <br> Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao |<img width="1002" alt="image" src="https://arxiv.org/html/2502.16235v2/x5.png"> |[Paper](https://arxiv.org/abs/2502.16235)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Soistesimmer/Fetch.svg?style=social&label=Star)](https://github.com/Soistesimmer/Fetch)<br>[Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls](https://arxiv.org/abs/2502.11183) <br> Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, Dong Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2502.11183v2/extracted/6301324/figures/method.png"> |[Github](https://github.com/Soistesimmer/Fetch) <br> [Paper](https://arxiv.org/abs/2502.11183)| [//]: #04/08



#### Other Optimal Methods
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[ProxyThinker: Test-Time Guidance through Small Visual Reasoners](https://arxiv.org/abs/2505.24872) <br> Zilin Xiao,Jaywon Koo,Siru Ouyang,Jefferson Hernandez,Yu Meng,Vicente Ordonez |<img width="1002" alt="image" src="https://arxiv.org/html/2505.24872v1/x3.png"> |[Paper](https://arxiv.org/abs/2505.24872)| [//]: #06/11
|[A*-Thought: Efficient Reasoning via Bidirectional Compression for Low-Resource Settings](https://arxiv.org/abs/2505.24550) <br> Xiaoang Xu,Shuo Wang,Xu Han,Zhenghao Liu,Huijia Wu,Peipei Li,Zhiyuan Liu,Maosong Sun,Zhaofeng He |<img width="1002" alt="image" src="https://arxiv.org/html/2505.24550v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.24550)| [//]: #06/11
|[Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models](https://arxiv.org/abs/2505.17697) <br> Zekai Zhao, Qi Liu, Kun Zhou, Zihan Liu, Yifei Shao, Zhiting Hu, Biwei Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17697v1/x7.png"> |[Paper](https://arxiv.org/abs/2505.17697)| [//]: #06/11
|[Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training](https://arxiv.org/abs/2505.14681) <br> Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, Zhaopeng Tu, Xiaolong Li, Dong Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14681v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14681)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/jiwonsong-dev/ReasoningPathCompression.svg?style=social&label=Star)](https://github.com/jiwonsong-dev/ReasoningPathCompression)<br>[Reasoning Path Compression: Compressing Generation Trajectories for Efficient LLM Reasoning](https://arxiv.org/abs/2505.13866) <br> Jiwon Song, Dongwon Jo, Yulhwa Kim, Jae-Joon Kim |<img width="1002" alt="image" src="figures/rpc_new.png"> |[Github](https://github.com/jiwonsong-dev/ReasoningPathCompression) <br> [Paper](https://arxiv.org/abs/2505.13866)| [//]: #05/22
|[RL of Thoughts: Navigating LLM Reasoning with Inference-time Reinforcement Learning](https://arxiv.org/abs/2505.14140) <br> Qianyue Hao, Sibo Li, Jian Yuan, Yong Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14140v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14140)| [//]: #05/22
|[Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity](https://arxiv.org/abs/2505.11107) <br> Chan-Jan Hsu, Davide Buffelli, Jamie McGowan, Feng-Ting Liao, Yi-Chang Chen, Sattar Vakili, Da-shan Shiu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11107v1/extracted/6445446/figures/gt_main_new.png"> |[Paper](https://arxiv.org/abs/2505.11107)| [//]: #05/19
|[![Star](https://img.shields.io/github/stars/LYC127/RPG.svg?style=social&label=Star)](https://github.com/LYC127/RPG) [![Publish](https://img.shields.io/badge/Conference-ACL_main_2025-blue)]()<br>[Rethinking Repetition Problems of LLMs in Code Generation](https://arxiv.org/abs/2505.10402) <br> Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li |<img width="1002" alt="image" src="figures/code_repeat.png"> |[Github](https://github.com/LYC127/RPG) <br> [Paper](https://arxiv.org/abs/2505.10402)| [//]: #05/18
|[Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping](https://arxiv.org/abs/2505.08392) <br> Ren Zhuang, Ben Wang, Shuifa Sun |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08392v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.08392)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/zch65458525/L2T.svg?style=social&label=Star)](https://github.com/zch65458525/L2T) [![Publish](https://img.shields.io/badge/Conference-IJCAI-blue)]()<br>[Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Learning](https://arxiv.org/abs/2505.06321) <br> Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu |<img width="1002" alt="image" src="figures/learn2think.png"> |[Github](https://github.com/zch65458525/L2T) <br> [Paper](https://arxiv.org/abs/2505.06321)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/hammoudhasan/SubthoughtReasoner.svg?style=social&label=Star)](https://github.com/hammoudhasan/SubthoughtReasoner)<br>[Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org/abs/2504.20708) <br> Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem |<img width="1002" alt="image" src="figures/beyond_last.png"> |[Github](https://github.com/hammoudhasan/SubthoughtReasoner) <br> [Paper](https://arxiv.org/abs/2504.20708)|[//]: #05/02
|[Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models](https://arxiv.org/abs/2504.20946) <br> Tyler McDonald, Ali Emami |<img width="1002" alt="image" src="https://arxiv.org/html/2504.20946v1/extracted/6399557/mainfig6.png"> |[Paper](https://arxiv.org/abs/2504.20946)| [//]: #04/30
|[![Star](https://img.shields.io/github/stars/Jikai0Wang/Speculative_CoT.svg?style=social&label=Star)](https://github.com/Jikai0Wang/Speculative_CoT)<br>[Efficient Reasoning for LLMs through Speculative Chain-of-Thought](https://arxiv.org/abs/2504.19095) <br> Jikai Wang, Juntao Li, Lijun Wu, Min Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.19095v1/extracted/6392438/images/scot.png"> |[Github](https://github.com/Jikai0Wang/Speculative_CoT) <br> [Paper](https://arxiv.org/abs/2504.19095)| [//]: #04/29
|[Dynamic Early Exit in Reasoning Models](https://arxiv.org/abs/2504.15895) <br> Chenxu Yang, Qingyi Si, Yongjie Duan, Zheliang Zhu, Chenyu Zhu, Zheng Lin, Li Cao, Weiping Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.15895v1/x3.png"> |[Paper](https://arxiv.org/abs/2504.15895)| [//]: #04/25
|[![Star](https://img.shields.io/github/stars/Parallel-Reasoning/APR.svg?style=social&label=Star)](https://github.com/Parallel-Reasoning/APR)<br>[Learning Adaptive Parallel Reasoning with Language Models](https://arxiv.org/abs/2504.15466) <br> Jiayi Pan, Xiuyu Li, Long Lian, Charlie Snell, Yifei Zhou, Adam Yala, Trevor Darrell, Kurt Keutzer, Alane Suhr |<img width="1002" alt="image" src="https://arxiv.org/html/2504.15466v1/x2.png"> |[Github](https://github.com/Parallel-Reasoning/APR) <br> [Paper](https://arxiv.org/abs/2504.15466)| [//]: #04/23
|[THOUGHTTERMINATOR: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models](https://arxiv.org/abs/2504.13367) <br> Xiao Pu, Michael Saxon, Wenyue Hua, William Yang Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.13367v1/x2.png"> |[Paper](https://arxiv.org/abs/2504.13367)| [//]: #04/21
|[![Star](https://img.shields.io/github/stars/imagination-research/sot.svg?style=social&label=Star)](https://github.com/imagination-research/sot) [![Publish](https://img.shields.io/badge/Conference-ICLR_2024-blue)]()<br>[Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation](https://arxiv.org/abs/2307.15337) <br> Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, Yu Wang |<img width="1002" alt="image" src="figures/skeleton_ot.png"> |[Github](https://github.com/imagination-research/sot) <br> [Paper](https://arxiv.org/abs/2307.15337)| [//]: #04/08
|[Adaptive Skeleton Graph Decoding](https://arxiv.org/abs/2402.12280) <br> Shuowei Jin, Yongji Wu, Haizhong Zheng, Qingzhao Zhang, Matthew Lentz, Z. Morley Mao, Atul Prakash, Feng Qian, Danyang Zhuo |<img width="1002" alt="image" src="figures/sgd.png"> |[Paper](https://arxiv.org/abs/2402.12280)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/BaohaoLiao/RSD.svg?style=social&label=Star)](https://github.com/BaohaoLiao/RSD)<br>[Reward-Guided Speculative Decoding for Efficient LLM Reasoning](https://arxiv.org/abs/2501.19324) <br> Baohao Liao, Yuhui Xu, Hanze Dong, Junnan Li, Christof Monz, Silvio Savarese, Doyen Sahoo, Caiming Xiong |<img width="1002" alt="image" src="figures/rsd.png"> |[Github](https://github.com/BaohaoLiao/RSD) <br> [Paper](https://arxiv.org/abs/2501.19324)| [//]: #04/08
|[Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models](https://arxiv.org/abs/2502.19918) <br> Yuan Sui, Yufei He, Tri Cao, Simeng Han, Bryan Hooi |<img width="1002" alt="image" src="figures/meta_reasoner.png"> |[Paper](https://arxiv.org/abs/2502.19918)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/qixucen/atom.svg?style=social&label=Star)](https://github.com/qixucen/atom)<br>[Atom of Thoughts for Markov LLM Test-Time Scaling](https://arxiv.org/abs/2502.12018) <br> Fengwei Teng, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo |<img width="1002" alt="image" src="figures/aot.png"> |[Github](https://github.com/qixucen/atom) <br> [Paper](https://arxiv.org/abs/2502.12018)| [//]: #04/08
|[DISC: Dynamic Decomposition Improves LLM Inference Scaling](https://arxiv.org/abs/2502.16706) <br> Jonathan Light, Wei Cheng, Wu Yue, Masafumi Oyamada, Mengdi Wang, Santiago Paternain, Haifeng Chen |<img width="1002" alt="image" src="figures/disc.png"> |[Paper](https://arxiv.org/abs/2502.16706)| [//]: #04/08
|[From Chaos to Order: The Atomic Reasoner Framework for Fine-grained Reasoning in Large Language Models](https://arxiv.org/abs/2503.15944) <br> Jinyi Liu, Yan Zheng, Rong Cheng, Qiyu Wu, Wei Guo, Fei Ni, Hebin Liang, Yifu Yuan, Hangyu Mao, Fuzheng Zhang, Jianye Hao |<img width="1002" alt="image" src="figures/ar.png"> |[Paper](https://arxiv.org/abs/2503.15944)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/Quinn777/AtomThink.svg?style=social&label=Star)](https://github.com/Quinn777/AtomThink)<br>[Can Atomic Step Decomposition Enhance the Self-structured Reasoning of Multimodal Large Models?](https://arxiv.org/abs/2503.06252) <br> Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang, Haoxiang Fan, Hanhui Li, Weiran Huang, Yihan Zeng, Yu-Jie Yuan, Jianhua Han, Lanqing Hong, Hang Xu, Xiaodan Liang |<img width="1002" alt="image" src="figures/atom.png"> |[Github](https://github.com/Quinn777/AtomThink) <br> [Paper](https://arxiv.org/abs/2503.06252)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314) <br> Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar |<img width="1002" alt="image" src="figures/tts_effective.png"> |[Paper](https://arxiv.org/abs/2408.03314)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/thu-wyz/inference_scaling.svg?style=social&label=Star)](https://github.com/thu-wyz/inference_scaling) [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models](https://arxiv.org/abs/2408.00724) <br> Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang |<img width="1002" alt="image" src="figures/scaling_law.png"> |[Github](https://github.com/thu-wyz/inference_scaling) <br> [Paper](https://arxiv.org/abs/2408.00724)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/CMU-AIRe/MRT.svg?style=social&label=Star)](https://github.com/CMU-AIRe/MRT)<br>[Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning](https://arxiv.org/abs/2503.07572) <br> Yuxiao Qu, Matthew Y. R. Yang, Amrith Setlur, Lewis Tunstall, Edward Emanuel Beeching, Ruslan Salakhutdinov, Aviral Kumar |<img width="1002" alt="image" src="figures/mrt.png"> |[Github](https://github.com/CMU-AIRe/MRT) <br> [Paper](https://arxiv.org/abs/2503.07572)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/ruipeterpan/specreason.svg?style=social&label=Star)](https://github.com/ruipeterpan/specreason)<br>[SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning](https://arxiv.org/abs/2504.07891) <br> Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali |<img width="1002" alt="image" src="figures/specreason.png"> |[Github](https://github.com/ruipeterpan/specreason) <br> [Paper](https://arxiv.org/abs/2504.07891)| [//]: #04/14



### Efficient Multimodal Reasoning
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/songw-zju/PixelThink.svg?style=social&label=Star)](https://github.com/songw-zju/PixelThink)<br>[PixelThink: Towards Efficient Chain-of-Pixel Reasoning](https://arxiv.org/abs/2505.23727) <br> Song Wang, Gongfan Fang, Lingdong Kong, Xiangtai Li, Jianyun Xu, Sheng Yang, Qiang Li, Jianke Zhu, Xinchao Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23727v1/x2.png"> |[Github](https://github.com/songw-zju/PixelThink) <br> [Paper](https://arxiv.org/abs/2505.23727)| [//]: #06/06
|[![Star](https://img.shields.io/github/stars/kokolerk/TON.svg?style=social&label=Star)](https://github.com/kokolerk/TON)<br>[Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models](https://arxiv.org/abs/2505.16854) <br> Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16854v1/x1.png"> |[Github](https://github.com/kokolerk/TON) <br> [Paper](https://arxiv.org/abs/2505.16854)| [//]: #05/24
|[MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing](https://arxiv.org/abs/2505.07984) <br> Aybora Koksal, A. Aydin Alatan |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07984v1/extracted/6432707/figures/sample_sam.png"> |[Paper](https://arxiv.org/abs/2505.07984)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/CodeGoat24/UnifiedReward.svg?style=social&label=Star)](https://github.com/CodeGoat24/UnifiedReward)<br>[Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.03318) <br> Yibin Wang, Zhimin Li, Yuhang Zang, Chunyu Wang, Qinglin Lu, Cheng Jin, Jiaqi Wang |<img width="1002" alt="image" src="figures/umrf.png"> |[Github](https://github.com/CodeGoat24/UnifiedReward) <br> [Paper](https://arxiv.org/abs/2505.03318)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/Quinn777/AtomThink.svg?style=social&label=Star)](https://github.com/Quinn777/AtomThink)<br>[Can Atomic Step Decomposition Enhance the Self-structured Reasoning of Multimodal Large Models?](https://arxiv.org/abs/2503.06252) <br> Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang, Haoxiang Fan, Hanhui Li, Weiran Huang, Yihan Zeng, Yu-Jie Yuan, Jianhua Han, Lanqing Hong, Hang Xu, Xiaodan Liang |<img width="1002" alt="image" src="figures/atom.png"> |[Github](https://github.com/Quinn777/AtomThink) <br> [Paper](https://arxiv.org/abs/2503.06252)| [//]: #04/08




###### Background Papers (multimodal reasoning)

| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.05331) <br> Xinyan Chen, Renrui Zhang, Dongzhi Jiang, Aojun Zhou, Shilin Yan, Weifeng Lin, Hongsheng Li |<img width="1002" alt="image" src="https://arxiv.org/html/2506.05331v1/x1.png"> |[Paper](https://arxiv.org/abs/2506.05331)| [//]: #06/11
|[GThinker: Towards General Multimodal Reasoning via Cue-Guided Rethinking](https://arxiv.org/abs/2506.01078) <br> Yufei Zhan, Ziheng Wu, Yousong Zhu, Rongkun Xue, Ruipu Luo, Zhenghao Chen, Can Zhang, Yifan Li, Zhentao He, Zheming Yang, Ming Tang, Minghui Qiu, Jinqiao Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2506.01078v1/x1.png"> |[Paper](https://arxiv.org/abs/2506.01078)| [//]: #06/11
|[Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering](https://arxiv.org/abs/2506.00806) <br> Songtao Jiang, Chenyi Zhou, Yan Zhang, Yeying Jin, Zuozhu Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.00806v1/x1.png"> |[Paper](https://arxiv.org/abs/2506.00806)| [//]: #06/11
|[Grounded Reinforcement Learning for Visual Reasoning](https://arxiv.org/abs/2505.23678) <br> Gabriel Sarch,Snigdha Saha,Naitik Khandelwal,Ayush Jain,Michael J. Tarr,Aviral Kumar,Katerina Fragkiadaki |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23678v1/extracted/6493857/Figures/Figure1_V4.jpg"> |[Paper](https://arxiv.org/abs/2505.23678)| [//]: #06/11
|[Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models](https://arxiv.org/abs/2505.23091) <br> Zeyu Liu,Yuhang Liu,Guanghao Zhu,Congkai Xie,Zhen Li,Jianbo Yuan,Xinyao Wang,Qing Li,Shing-Chi Cheung,Shengyu Zhang,Fei Wu,Hongxia Yang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23091v2/extracted/6518453/images_folder/mmr1_framework_update.png"> |[Paper](https://arxiv.org/abs/2505.23091)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/Liar406/Look_Again.svg?style=social&label=Star)](https://github.com/Liar406/Look_Again)<br>[Qwen Look Again: Guiding Vision-Language Reasoning Models to Re-attention Visual Information](https://arxiv.org/abs/2505.23558) <br> Xu Chu, Xinrong Chen, Guanyu Wang, Zhijie Tan, Kui Huang, Wenyu Lv, Tong Mo, Weiping Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23558v2/x5.png"> |[Github](https://github.com/Liar406/Look_Again) <br> [Paper](https://arxiv.org/abs/2505.23558)| [//]: #06/11
|[Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought](https://arxiv.org/abs/2505.23766) <br> Yunze Man,De-An Huang,Guilin Liu,Shiwei Sheng,Shilong Liu,Liang-Yan Gui,Jan Kautz,Yu-Xiong Wang,Zhiding Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.23766v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.23766)| [//]: #06/11
|[Understand, Think, and Answer: Advancing Visual Reasoning with Large Multimodal Models](https://arxiv.org/abs/2505.20753) <br> Yufei Zhan, Hongyin Zhao, Yousong Zhu, Shurong Zheng, Fan Yang, Ming Tang, Jinqiao Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.20753v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.20753)| [//]: #06/11
|[Point-RFT: Improving Multimodal Reasoning with Visually Grounded Reinforcement Finetuning](https://arxiv.org/abs/2505.19702) <br> Minheng Ni, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Kevin Lin, Wangmeng Zuo, Lijuan Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.19702v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.19702)| [//]: #06/11
|[Ground-R1: Incentivizing Grounded Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2505.20272) <br> Meng Cao, Haoze Zhao, Can Zhang, Xiaojun Chang, Ian Reid, Xiaodan Liang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.20272v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.20272)| [//]: #06/11
|[SATORI-R1: Incentivizing Multimodal Reasoning with Spatial Grounding and Verifiable Rewards](https://arxiv.org/abs/2505.19094) <br> Chuming Shen, Wei Wei, Xiaoye Qu, Yu Cheng |<img width="1002" alt="image" src="figures/sato.png"> |[Paper](https://arxiv.org/abs/2505.19094)| [//]: #06/11
|[Don't Look Only Once: Towards Multimodal Interactive Reasoning with Selective Visual Revisitation](https://arxiv.org/abs/2505.18842) <br> Jiwan Chung, Junhyeok Kim, Siyeol Kim, Jaeyoung Lee, Min Soo Kim, Youngjae Yu |<img width="1002" alt="image" src="figures/v1.png"> |[Paper](https://arxiv.org/abs/2505.18842)| [//]: #06/11
|[Visual Abstract Thinking Empowers Multimodal Reasoning](https://arxiv.org/abs/2505.20164) <br> Dairu Liu, Ziyue Wang, Minyuan Ruan, Fuwen Luo, Chi Chen, Peng Li, Yang Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.20164v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.20164)| [//]: #06/11
|[VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use](https://arxiv.org/abs/2505.19255) <br> Mingyuan Wu, Jingcheng Yang, Jize Jiang, Meitang Li, Kaizhuo Yan, Hanchao Yu, Minjia Zhang, Chengxiang Zhai, Klara Nahrstedt |<img width="1002" alt="image" src="figures/vtool.png"> |[Paper](https://arxiv.org/abs/2505.19255)| [//]: #06/11
|[DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning](https://arxiv.org/abs/2505.20241) <br> Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie |<img width="1002" alt="image" src="https://arxiv.org/html/2505.20241v2/x1.png"> |[Paper](https://arxiv.org/abs/2505.20241)| [//]: #06/11
|[FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving](https://arxiv.org/abs/2505.17685) <br> Shuang Zeng, Xinyuan Chang, Mengwei Xie, Xinran Liu, Yifan Bai, Zheng Pan, Mu Xu, Xing Wei |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17685v1/extracted/6470865/fig/compare.png"> |[Paper](https://arxiv.org/abs/2505.17685)| [//]: #06/11
|[![Star](https://img.shields.io/github/stars/guozix/DVLR.svg?style=social&label=Star)](https://github.com/guozix/DVLR)<br>[Decoupled Visual Interpretation and Linguistic Reasoning for Math Problem Solving](https://arxiv.org/abs/2505.17609) <br> Zixian Guo, Ming Liu, Zhilong Ji, Jinfeng Bai, Lei Zhang, Wangmeng Zuo |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17609v1/x1.png"> |[Github](https://github.com/guozix/DVLR) <br> [Paper](https://arxiv.org/abs/2505.17609)| [//]: #06/11
|[Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework](https://arxiv.org/abs/2505.17019) <br> Chenhao Zhang, Yazhe Niu |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17019v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.17019)| [//]: #05/24
|[Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning](https://arxiv.org/abs/2505.15966) <br> Alex Su, Haozhe Wang, Weimin Ren, Fangzhen Lin, Wenhu Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15966v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.15966)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/hcwei13/FRANK-ZERO-Inference.svg?style=social&label=Star)](https://github.com/hcwei13/FRANK-ZERO-Inference)<br>[Training-Free Reasoning and Reflection in MLLMs](https://arxiv.org/abs/2505.16151) <br> Hongchen Wei, Zhenzhong Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16151v1/x1.png"> |[Github](https://github.com/hcwei13/FRANK-ZERO-Inference) <br> [Paper](https://arxiv.org/abs/2505.16151)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/HJYao00/R1-ShareVL.svg?style=social&label=Star)](https://github.com/HJYao00/R1-ShareVL)<br>[R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO](https://arxiv.org/abs/2505.16673) <br> Huanjin Yao, Qixiang Yin, Jingyi Zhang, Min Yang, Yibo Wang, Wenhao Wu, Fei Su, Li Shen, Minghui Qiu, Dacheng Tao, Jiaxing Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16673v1/x2.png"> |[Github](https://github.com/HJYao00/R1-ShareVL) <br> [Paper](https://arxiv.org/abs/2505.16673)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/kxfan2002/SophiaVL-R1.svg?style=social&label=Star)](https://github.com/kxfan2002/SophiaVL-R1)<br>[SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward](https://arxiv.org/abs/2505.17018) <br> Kaixuan Fan, Kaituo Feng, Haoming Lyu, Dongzhan Zhou, Xiangyu Yue |<img width="1002" alt="image" src="https://arxiv.org/html/2505.17018v1/x1.png"> |[Github](https://github.com/kxfan2002/SophiaVL-R1) <br> [Paper](https://arxiv.org/abs/2505.17018)| [//]: #05/24
|[VLM-R3: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought](https://arxiv.org/abs/2505.16192) <br> Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16192v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.16192)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/Cratileo/D2R.svg?style=social&label=Star)](https://github.com/Cratileo/D2R)<br>[Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org/abs/2505.16579) <br> Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16579v1/x1.png"> |[Github](https://github.com/Cratileo/D2R) <br> [Paper](https://arxiv.org/abs/2505.16579)| [//]: #05/24
|[GRIT: Teaching MLLMs to Think with Images](https://arxiv.org/abs/2505.15879) <br> Yue Fan, Xuehai He, Diji Yang, Kaizhi Zheng, Ching-Chen Kuo, Yuting Zheng, Sravana Jyothi Narayanaraju, Xinze Guan, Xin Eric Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15879v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.15879)| [//]: #05/24
|[UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning](https://arxiv.org/abs/2505.14231) <br> Sule Bai, Mingxing Li, Yong Liu, Jing Tang, Haoji Zhang, Lei Sun, Xiangxiang Chu, Yansong Tang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14231v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.14231)| [//]: #05/23
|[![Star](https://img.shields.io/github/stars/Gen-Verse/MMaDA.svg?style=social&label=Star)](https://github.com/Gen-Verse/MMaDA)<br>[MMaDA: Multimodal Large Diffusion Language Models](https://arxiv.org/abs/2505.15809) <br> Ling Yang, Ye Tian, Bowen Li, Xinchen Zhang, Ke Shen, Yunhai Tong, Mengdi Wang |<img width="1002" alt="image" src="figures/mmaba.png"> |[Github](https://github.com/Gen-Verse/MMaDA) <br> [Paper](https://arxiv.org/abs/2505.15809)| [//]: #05/22
|[Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought](https://arxiv.org/abs/2505.15510) <br> Zihui Cheng, Qiguang Chen, Xiao Xu, Jiaqi Wang, Weiyun Wang, Hao Fei, Yidong Wang, Alex Jinpeng Wang, Zhi Chen, Wanxiang Che, Libo Qin |<img width="1002" alt="image" src="https://arxiv.org/html/2505.15510v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.15510)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/maifoundations/Visionary-R1.svg?style=social&label=Star)](https://github.com/maifoundations/Visionary-R1)<br>[Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning](https://arxiv.org/abs/2505.14677) <br> Jiaer Xia, Yuhang Zang, Peng Gao, Yixuan Li, Kaiyang Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14677v1/x3.png"> |[Github](https://github.com/maifoundations/Visionary-R1) <br> [Paper](https://arxiv.org/abs/2505.14677)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/dvlab-research/VisionReasoner.svg?style=social&label=Star)](https://github.com/dvlab-research/VisionReasoner)<br>[VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning](https://arxiv.org/abs/2505.12081) <br> Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12081v1/x1.png"> |[Github](https://github.com/dvlab-research/VisionReasoner) <br> [Paper](https://arxiv.org/abs/2505.12081)| [//]: #05/20
|[![Star](https://img.shields.io/github/stars/ModalMinds/MM-PRM.svg?style=social&label=Star)](https://github.com/ModalMinds/MM-PRM)<br>[MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision](https://arxiv.org/abs/2505.13427) <br> Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao |<img width="1002" alt="image" src="figures/mmprm.png"> |[Github](https://github.com/ModalMinds/MM-PRM) <br> [Paper](https://arxiv.org/abs/2505.13427)| [//]: #05/20
|[CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning](https://arxiv.org/abs/2505.11830) <br> Hongbo Jin, Ruyang Liu, Wenhao Zhang, Guibo Luo, Ge Li |<img width="1002" alt="image" src="figures/video_cot.png"> |[Paper](https://arxiv.org/abs/2505.11830)| [//]: #05/20
|[Visual Planning: Let's Think Only with Images](https://arxiv.org/abs/2505.11409) <br> Yi Xu, Chengzu Li, Han Zhou, Xingchen Wan, Caiqi Zhang, Anna Korhonen, Ivan VuliÄ‡ |<img width="1002" alt="image" src="https://arxiv.org/html/2505.11409v1/x2.png"> |[Paper](https://arxiv.org/abs/2505.11409)| [//]: #05/19
|[![Star](https://img.shields.io/github/stars/microsoft/x-reasoner.svg?style=social&label=Star)](https://github.com/microsoft/x-reasoner)<br>[X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains](https://arxiv.org/abs/2505.03981) <br> Qianchu Liu, Sheng Zhang, Guanghui Qin, Timothy Ossowski, Yu Gu, Ying Jin, Sid Kiblawi, Sam Preston, Mu Wei, Paul Vozila, Tristan Naumann, Hoifung Poon |<img width="1002" alt="image" src="https://arxiv.org/html/2505.03981v1/x1.png"> |[Github](https://github.com/microsoft/x-reasoner) <br> [Paper](https://arxiv.org/abs/2505.03981)| [//]: #05/18
|[Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning](https://arxiv.org/abs/2505.07263) <br> Xiaokun Wang, Chris, Jiangbo Pei, Wei Shen, Yi Peng, Yunzhuo Hao, Weijie Qiu, Ai Jian, Tianyidan Xie, Xuchen Song, Yang Liu, Yahui Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07263v1/extracted/6430395/figure/distribution.png"> |[Paper](https://arxiv.org/abs/2505.07263)| [//]: #05/18
| [![Publish](https://img.shields.io/badge/Conference-ACL_findings_2025-blue)]()<br>[MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning](https://arxiv.org/abs/2505.10557) <br> Ke Wang, Junting Pan, Linda Wei, Aojun Zhou, Weikang Shi, Zimu Lu, Han Xiao, Yunqiao Yang, Houxing Ren, Mingjie Zhan, Hongsheng Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10557v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.10557)| [//]: #05/18
|[![Star](https://img.shields.io/github/stars/ChengJade/VISTAR.svg?style=social&label=Star)](https://github.com/ChengJade/VISTAR)<br>[Visually Interpretable Subtask Reasoning for Visual Question Answering](https://arxiv.org/abs/2505.08084) <br> Yu Cheng, Arushi Goel, Hakan Bilen |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08084v1/x1.png"> |[Github](https://github.com/ChengJade/VISTAR) <br> [Paper](https://arxiv.org/abs/2505.08084)| [//]: #05/18
|[![Star](https://img.shields.io/github/stars/shiqichen17/VLM_Merging.svg?style=social&label=Star)](https://github.com/shiqichen17/VLM_Merging) [![Publish](https://img.shields.io/badge/Conference-ICML_2025-blue)]()<br>[Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging](https://arxiv.org/abs/2505.05464) <br> Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He |<img width="1002" alt="image" src="https://arxiv.org/html/2505.05464v1/x1.png"> |[Github](https://github.com/shiqichen17/VLM_Merging) <br> [Paper](https://arxiv.org/abs/2505.05464)| [//]: #05/18
|[![Star](https://img.shields.io/github/stars/SkyworkAI/Skywork-R1V.svg?style=social&label=Star)](https://github.com/SkyworkAI/Skywork-R1V)<br>[Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning](https://arxiv.org/abs/2504.16656) <br> Chris, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei, Jianhao Zhang, Yunzhuo Hao, Xuchen Song, Yang Liu, Yahui Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2504.16656v2/extracted/6389842/figure/ssb_diagram.png"> |[Github](https://github.com/SkyworkAI/Skywork-R1V) <br> [Paper](https://arxiv.org/abs/2504.16656)| [//]: #04/29


###### Technical Report

* [Seed1.5-VL Technical Report](https://arxiv.org/abs/2505.07062). seed team. [[Paper]](https://arxiv.org/abs/2505.07062)


### Evaluation and Benchmarks


#### Metric
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/abs/2412.21187) <br> Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2412.21187v2/x2.png"> |[Paper](https://arxiv.org/abs/2412.21187)|[//]: #03/16
|[![Star](https://img.shields.io/github/stars/horseee/CoT-Valve.svg?style=social&label=Star)](https://github.com/horseee/CoT-Valve)<br>[CoT-Valve: Length-Compressible Chain-of-Thought Tuning](https://arxiv.org/abs/2502.09601) <br> Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang |<img width="1002" alt="image" src="figures/cot_valve.png"> |[Github](https://github.com/horseee/CoT-Valve) <br> [Paper](https://arxiv.org/abs/2502.09601)|[//]: #03/16
|[![Star](https://img.shields.io/github/stars/breckbaldwin/llm-stability.svg?style=social&label=Star)](https://github.com/breckbaldwin/llm-stability)<br>[Non-Determinism of "Deterministic" LLM Settings](https://arxiv.org/abs/2408.04667) <br> Berk Atil, Sarp Aykent, Alexa Chittams, Lisheng Fu, Rebecca J. Passonneau, Evan Radcliffe, Guru Rajan Rajagopal, Adam Sloan, Tomasz Tudrej, Ferhan Ture, Zhe Wu, Lixinyu Xu, Breck Baldwin |<img width="1002" alt="image" src="https://arxiv.org/html/2408.04667v5/extracted/6331111/max_min_diff.png"> |[Github](https://github.com/breckbaldwin/llm-stability) <br> [Paper](https://arxiv.org/abs/2408.04667)| [//]: #04/08
|[The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks](https://arxiv.org/abs/2502.08235) <br> Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis Gaspar Schroeder, Tian Xia, Huanzhi Mao, Nicholas Thumiger, Aditya Desai, Ion Stoica, Ana Klimovic, Graham Neubig, Joseph E. Gonzalez |<img width="1002" alt="image" src="figures/openhands.png"> |[Paper](https://arxiv.org/abs/2502.08235)| [//]: #04/08
|[Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374) <br> Mark Chen, Jerry Tworek, et al. |<img width="1002" alt="image" src="figures/passk.png"> |[Paper](https://arxiv.org/abs/2107.03374)| [//]: #04/08
|[Ï„-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains](https://arxiv.org/abs/2406.12045) <br> Shunyu Yao, Noah Shinn, Pedram Razavi, Karthik Narasimhan |<img width="1002" alt="image" src="figures/agent_bench.png"> |[Paper](https://arxiv.org/abs/2406.12045)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/open-compass/GPassK.svg?style=social&label=Star)](https://github.com/open-compass/GPassK)<br>[Are Your LLMs Capable of Stable Reasoning?](https://arxiv.org/abs/2412.13147) <br> Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2412.13147v3/x1.png"> |[Github](https://github.com/open-compass/GPassK) <br> [Paper](https://arxiv.org/abs/2412.13147)| [//]: #04/08


#### Benchmarks and Datasets
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/fscdc/ReasonMap.svg?style=social&label=Star)](https://github.com/fscdc/ReasonMap)<br>[Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps](https://arxiv.org/abs/2505.18675) <br> Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.18675v2/x1.png"> |[Github](https://github.com/fscdc/ReasonMap) <br> [Paper](https://arxiv.org/abs/2505.18675)| [//]: #06/11
|[ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations](https://arxiv.org/abs/2505.14404) <br> Xuecheng Wu, Jiaxing Liu, Danlei Huang, Xiaoyu Li, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao, Junxiao Xue |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14404v1/x3.png"> |[Paper](https://arxiv.org/abs/2505.14404)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/Liyan06/ChartMuseum.svg?style=social&label=Star)](https://github.com/Liyan06/ChartMuseum)<br>[ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models](https://arxiv.org/abs/2505.13444) <br> Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, Bodun Hu, Juan Diego Rodriguez, Puyuan Peng, Greg Durrett |<img width="1002" alt="image" src="figures/chartmuseum.png"> |[Github](https://github.com/Liyan06/ChartMuseum) <br> [Paper](https://arxiv.org/abs/2505.13444)| [//]: #05/20
|[Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org/abs/2505.10937) <br> Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10937v1/extracted/6444682/fig1-v2.png"> |[Paper](https://arxiv.org/abs/2505.10937)| [//]: #05/19
|[StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation](https://arxiv.org/abs/2505.10292) <br> Daniel A. P. Oliveira, David Martins de Matos |<img width="1002" alt="image" src="figures/story.png"> |[Paper](https://arxiv.org/abs/2505.10292)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/alibaba-damo-academy/VCBench.svg?style=social&label=Star)](https://github.com/alibaba-damo-academy/VCBench)<br>[Benchmarking Multimodal Mathematical Reasoning with Explicit Visual Dependency](https://arxiv.org/abs/2504.18589) <br> Zhikai Wang, Jiashuo Sun, Wenqi Zhang, Zhiqiang Hu, Xin Li, Fan Wang, Deli Zhao |<img width="1002" alt="image" src="https://arxiv.org/html/2504.18589v1/x1.png"> |[Github](https://github.com/alibaba-damo-academy/VCBench) <br> [Paper](https://arxiv.org/abs/2504.18589)| [//]: #04/29
|[![Star](https://img.shields.io/github/stars/Goodman-liyu/CipherBank.svg?style=social&label=Star)](https://github.com/Goodman-liyu/CipherBank)<br>[CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges](https://arxiv.org/abs/2504.19093) <br> Yu Li, Qizhi Pei, Mengyuan Sun, Honglin Lin, Chenlin Ming, Xin Gao, Jiang Wu, Conghui He, Lijun Wu |<img width="1002" alt="image" src="https://arxiv.org/html/2504.19093v1/x2.png"> |[Github](https://github.com/Goodman-liyu/CipherBank) <br> [Paper](https://arxiv.org/abs/2504.19093)| [//]: #04/29
|[![Star](https://img.shields.io/github/stars/VisuLogic-Benchmark/VisuLogic-Eval.svg?style=social&label=Star)](https://github.com/VisuLogic-Benchmark/VisuLogic-Eval)<br>[VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models](https://arxiv.org/abs/2504.15279) <br> Weiye Xu, Jiahao Wang, Weiyun Wang, Zhe Chen, Wengang Zhou, Aijun Yang, Lewei Lu, Houqiang Li, Xiaohua Wang, Xizhou Zhu, Wenhai Wang, Jifeng Dai, Jinguo Zhu |<img width="1002" alt="image" src="https://arxiv.org/html/2504.15279v1/x1.png"> |[Github](https://github.com/VisuLogic-Benchmark/VisuLogic-Eval) <br> [Paper](https://arxiv.org/abs/2504.15279)| [//]: #04/25
|[LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception](https://arxiv.org/abs/2504.15362) <br> Yuan-Hong Liao, Sven Elflein, Liu He, Laura Leal-TaixÃ©, Yejin Choi, Sanja Fidler, David Acuna |<img width="1002" alt="image" src="https://arxiv.org/html/2504.15362v1/x1.png"> |[Paper](https://arxiv.org/abs/2504.15362)| [//]: #04/23
|[THOUGHTTERMINATOR: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models](https://arxiv.org/abs/2504.13367) <br> Xiao Pu, Michael Saxon, Wenyue Hua, William Yang Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.13367v1/x2.png"> |[Paper](https://arxiv.org/abs/2504.13367)| [//]: #04/21
|[Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/abs/2412.21187) <br> Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2412.21187v2/x2.png"> |[Paper](https://arxiv.org/abs/2412.21187)|[//]: #03/16
|[The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks](https://arxiv.org/abs/2502.08235) <br> Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis Gaspar Schroeder, Tian Xia, Huanzhi Mao, Nicholas Thumiger, Aditya Desai, Ion Stoica, Ana Klimovic, Graham Neubig, Joseph E. Gonzalez |<img width="1002" alt="image" src="figures/openhands.png"> |[Paper](https://arxiv.org/abs/2502.08235)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/divelab/sys2bench.svg?style=social&label=Star)](https://github.com/divelab/sys2bench)<br>[Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights](https://arxiv.org/abs/2502.12521) <br> Shubham Parashar, Blake Olson, Sambhav Khurana, Eric Li, Hongyi Ling, James Caverlee, Shuiwang Ji |<img width="1002" alt="image" src="https://arxiv.org/html/2502.12521v1/x1.png"> |[Github](https://github.com/divelab/sys2bench) <br> [Paper](https://arxiv.org/abs/2502.12521)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/usail-hkust/benchmark_inference_time_computation_LLM.svg?style=social&label=Star)](https://github.com/usail-hkust/benchmark_inference_time_computation_LLM)<br>[Bag of Tricks for Inference-time Computation of LLM Reasoning](https://arxiv.org/abs/2502.07191) <br> Fan Liu, Wenshuo Chao, Naiqiang Tan, Hao Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2502.07191v4/x1.png"> |[Github](https://github.com/usail-hkust/benchmark_inference_time_computation_LLM) <br> [Paper](https://arxiv.org/abs/2502.07191)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/RyanLiu112/compute-optimal-tts.svg?style=social&label=Star)](https://github.com/RyanLiu112/compute-optimal-tts)<br>[Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling](https://arxiv.org/abs/2502.06703) <br> Runze Liu, Junqi Gao, Jian Zhao, Kaiyan Zhang, Xiu Li, Biqing Qi, Wanli Ouyang, Bowen Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2502.06703v1/x2.png"> |[Github](https://github.com/RyanLiu112/compute-optimal-tts) <br> [Paper](https://arxiv.org/abs/2502.06703)| [//]: #04/08
|[DNA Bench: When Silence is Smarter -- Benchmarking Over-Reasoning in Reasoning LLMs](https://arxiv.org/abs/2503.15793) <br> Masoud Hashemi, Oluwanifemi Bamgbose, Sathwik Tejaswi Madhusudhan, Jishnu Sethumadhavan Nair, Aman Tiwari, Vikas Yadav |<img width="1002" alt="image" src="https://arxiv.org/html/2503.15793v3/x5.png"> |[Paper](https://arxiv.org/abs/2503.15793)| [//]: #04/08
|[S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models](https://arxiv.org/abs/2504.10368) <br> Wenyuan Zhang, Shuaiyi Nie, Xinghua Zhang, Zefeng Zhang, Tingwen Liu |<img width="1002" alt="image" src="figures/S1_Bench.png"> |[Paper](https://arxiv.org/abs/2504.10368)| [//]: #04/14
|[![Star](https://img.shields.io/github/stars/zhishuifeiqian/VCR-Bench.svg?style=social&label=Star)](https://github.com/zhishuifeiqian/VCR-Bench)<br>[VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning](https://arxiv.org/abs/2504.07956) <br> Yukun Qi, Yiming Zhao, Yu Zeng, Xikun Bao, Wenxuan Huang, Lin Chen, Zehui Chen, Jie Zhao, Zhongang Qi, Feng Zhao |<img width="1002" alt="image" src="figures/video.png"> |[Github](https://github.com/zhishuifeiqian/VCR-Bench) <br> [Paper](https://arxiv.org/abs/2504.07956)| [//]: #04/16


### Background Papers
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://arxiv.org/abs/2505.16400) <br> Yang Chen, Zhuolin Yang, Zihan Liu, Chankyu Lee, Peng Xu, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping |<img width="1002" alt="image" src="https://arxiv.org/html/2505.16400v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.16400)| [//]: #05/24
|[![Star](https://img.shields.io/github/stars/thu-coai/BARREL.svg?style=social&label=Star)](https://github.com/thu-coai/BARREL)<br>[BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs](https://arxiv.org/abs/2505.13529) <br> Junxiao Yang, Jinzhe Tu, Haoran Liu, Xiaoce Wang, Chujie Zheng, Zhexin Zhang, Shiyao Cui, Caishun Chen, Tiantian He, Hongning Wang, Yew-Soon Ong, Minlie Huang |<img width="1002" alt="image" src="figures/BARREL.png"> |[Github](https://github.com/thu-coai/BARREL) <br> [Paper](https://arxiv.org/abs/2505.13529)| [//]: #05/23
|[![Star](https://img.shields.io/github/stars/kaiwenzha/rl-tango.svg?style=social&label=Star)](https://github.com/kaiwenzha/rl-tango)<br>[RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning](https://arxiv.org/abs/2505.15034) <br> Kaiwen Zha, Zhengqi Gao, Maohao Shen, Zhang-Wei Hong, Duane S. Boning, Dina Katabi |<img width="1002" alt="image" src="figures/Tango.png"> |[Github](https://github.com/kaiwenzha/rl-tango) <br> [Paper](https://arxiv.org/abs/2505.15034)| [//]: #05/23
|[Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision](https://arxiv.org/abs/2505.14999) <br> Eric Hanchen Jiang, Haozheng Luo, Shengyuan Pang, Xiaomin Li, Zhenting Qi, Hengli Li, Cheng-Fu Yang, Zongyu Lin, Xinfeng Li, Hao Xu, Kai-Wei Chang, Ying Nian Wu |<img width="1002" alt="image" src="figures/eorm.png"> |[Paper](https://arxiv.org/abs/2505.14999)| [//]: #05/22
|[Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings](https://arxiv.org/abs/2505.13718) <br> Safal Shrestha, Minwu Kim, Aadim Nepal, Anubhav Shrestha, Keith Ross |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13718v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.13718)| [//]: #05/22
|[Reasoning Models Better Express Their Confidence](https://arxiv.org/abs/2505.14489) <br> Dongkeun Yoon, Seungone Kim, Sohee Yang, Sunkyoung Kim, Soyeon Kim, Yongil Kim, Eunbi Choi, Yireun Kim, Minjoon Seo |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14489v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14489)| [//]: #05/22
|[Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning](https://arxiv.org/abs/2505.14684) <br> Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, Yueting Zhuang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14684v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.14684)| [//]: #05/22
|[![Star](https://img.shields.io/github/stars/krystalan/DRT.svg?style=social&label=Star)](https://github.com/krystalan/DRT)<br>[ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning](https://arxiv.org/abs/2505.12996) <br> Jiaan Wang, Fandong Meng, Jie Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2505.12996v1/x4.png"> |[Github](https://github.com/krystalan/DRT) <br> [Paper](https://arxiv.org/abs/2505.12996)| [//]: #05/20
|[![Star](https://img.shields.io/github/stars/LightChen233/reasoning-boundary.svg?style=social&label=Star)](https://github.com/LightChen233/reasoning-boundary)<br>[RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning](https://arxiv.org/abs/2505.13307) <br> Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che |<img width="1002" alt="image" src="https://arxiv.org/html/2505.13307v1/x1.png"> |[Github](https://github.com/LightChen233/reasoning-boundary) <br> [Paper](https://arxiv.org/abs/2505.13307)| [//]: #05/20
|[Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/abs/2505.03335) <br> Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.03335v2/x3.png"> |[Paper](https://arxiv.org/abs/2505.03335)| [//]: #05/19
|[![Star](https://img.shields.io/github/stars/tongxuluo/LeaP.svg?style=social&label=Star)](https://github.com/tongxuluo/LeaP)<br>[Learning from Peers in Reasoning Models](https://arxiv.org/abs/2505.07787) <br> Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07787v1/extracted/6432669/figures/main.png"> |[Github](https://github.com/tongxuluo/LeaP) <br> [Paper](https://arxiv.org/abs/2505.07787)| [//]: #05/19
|[![Star](https://img.shields.io/github/stars/zhiyuanhubj/Meta-Ability-Alignment.svg?style=social&label=Star)](https://github.com/zhiyuanhubj/Meta-Ability-Alignment)<br>[Beyond Aha!: Toward Systematic Meta-Abilities Alignment in Large Reasoning Models](https://arxiv.org/abs/2505.10554) <br> Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10554v1/x2.png"> |[Github](https://github.com/zhiyuanhubj/Meta-Ability-Alignment) <br> [Paper](https://arxiv.org/abs/2505.10554)| [//]: #05/19
|[![Star](https://img.shields.io/github/stars/zhaochen0110/OpenThinkIMG.svg?style=social&label=Star)](https://github.com/zhaochen0110/OpenThinkIMG)<br>[OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning](https://arxiv.org/abs/2505.08617) <br> Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu, Juntao Li, Xiaoye Qu, Yu Cheng |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08617v1/x1.png"> |[Github](https://github.com/zhaochen0110/OpenThinkIMG) <br> [Paper](https://arxiv.org/abs/2505.08617)| [//]: #05/19
|[The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org/abs/2505.10185) <br> Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo |<img width="1002" alt="image" src="figures/cotencyc.png"> |[Paper](https://arxiv.org/abs/2505.10185)| [//]: #05/19
|[Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models](https://arxiv.org/abs/2505.10446) <br> Zemin Huang, Zhiyang Chen, Zijun Wang, Tiancheng Li, Guo-Jun Qi |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10446v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.10446)| [//]: #05/18
|[J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning](https://arxiv.org/abs/2505.10320) <br> Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha |<img width="1002" alt="image" src="https://arxiv.org/html/2505.10320v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.10320)| [//]: #05/18
|[INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning](https://arxiv.org/abs/2505.07291) <br> Prime Intellect Team, Sami Jaghouar, Justus Mattern, Jack Min Ong, Jannik Straube, Manveer Basra, Aaron Pazdera, Kushal Thaman, Matthew Di Ferrante, Felix Gabriel, Fares Obeid, Kemal Erdem, Michael Keiblinger, Johannes Hagemann |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07291v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.07291)| [//]: #05/18
|[AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale](https://arxiv.org/abs/2505.08311) <br> Yunjie Ji, Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Han Zhao, Xiangang Li |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08311v1/extracted/6434266/benchmark.png"> |[Paper](https://arxiv.org/abs/2505.08311)| [//]: #05/18
|[![Star](https://img.shields.io/github/stars/solitaryzero/CoTs_are_Variables.svg?style=social&label=Star)](https://github.com/solitaryzero/CoTs_are_Variables)<br>[Chain-of-Thought Tokens are Computer Program Variables](https://arxiv.org/abs/2505.04955) <br> Fangwei Zhu, Peiyi Wang, Zhifang Sui |<img width="1002" alt="image" src="https://arxiv.org/html/2505.04955v1/x2.png"> |[Github](https://github.com/solitaryzero/CoTs_are_Variables) <br> [Paper](https://arxiv.org/abs/2505.04955)| [//]: #05/17
|[![Star](https://img.shields.io/github/stars/xiaomimimo/MiMo.svg?style=social&label=Star)](https://github.com/xiaomimimo/MiMo)<br>[MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining](https://arxiv.org/abs/2505.07608) <br> Xiaomi LLM-Core Team |<img width="1002" alt="image" src="https://arxiv.org/html/2505.07608v1/x1.png"> |[Github](https://github.com/xiaomimimo/MiMo) <br> [Paper](https://arxiv.org/abs/2505.07608)| [//]: #05/17
|[Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](https://arxiv.org/abs/2505.00875) <br> Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00875v1/x1.png"> |[Paper](https://arxiv.org/abs/2505.00875)| [//]: #05/05
|[Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs](https://arxiv.org/abs/2505.00127) <br> Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie |<img width="1002" alt="image" src="https://arxiv.org/html/2505.00127v1/extracted/6402775/Figures/token_vs_accuracy_nonlinear_1x2.png"> |[Paper](https://arxiv.org/abs/2505.00127)|[//]: #05/02
|[![Star](https://img.shields.io/github/stars/RUC-NLPIR/WebThinker.svg?style=social&label=Star)](https://github.com/RUC-NLPIR/WebThinker)<br>[WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/abs/2504.21776) <br> Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou |<img width="1002" alt="image" src="figures/webthinker.png"> |[Github](https://github.com/RUC-NLPIR/WebThinker) <br> [Paper](https://arxiv.org/abs/2504.21776)|[//]: #05/02
|[![Star](https://img.shields.io/github/stars/hammoudhasan/SubthoughtReasoner.svg?style=social&label=Star)](https://github.com/hammoudhasan/SubthoughtReasoner)<br>[Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think](https://arxiv.org/abs/2504.20708) <br> Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem |<img width="1002" alt="image" src="figures/beyond_last.png"> |[Github](https://github.com/hammoudhasan/SubthoughtReasoner) <br> [Paper](https://arxiv.org/abs/2504.20708)|[//]: #05/02
|[![Star](https://img.shields.io/github/stars/ypwang61/One-Shot-RLVR.svg?style=social&label=Star)](https://github.com/ypwang61/One-Shot-RLVR)<br>[Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org/abs/2504.20571) <br> Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen |<img width="1002" alt="image" src="https://arxiv.org/html/2504.20571v1/x3.png"> |[Github](https://github.com/ypwang61/One-Shot-RLVR) <br> [Paper](https://arxiv.org/abs/2504.20571)|[//]: #04/30
|[![Star](https://img.shields.io/github/stars/SkyworkAI/Skywork-R1V.svg?style=social&label=Star)](https://github.com/SkyworkAI/Skywork-R1V)<br>[Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning](https://arxiv.org/abs/2504.16656) <br> Chris, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei, Jianhao Zhang, Yunzhuo Hao, Xuchen Song, Yang Liu, Yahui Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2504.16656v2/extracted/6389842/figure/ssb_diagram.png"> |[Github](https://github.com/SkyworkAI/Skywork-R1V) <br> [Paper](https://arxiv.org/abs/2504.16656)| [//]: #04/29
|[![Star](https://img.shields.io/github/stars/LeapLabTHU/limit-of-RLVR.svg?style=social&label=Star)](https://github.com/LeapLabTHU/limit-of-RLVR)<br>[Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org/abs/2504.13837) <br> Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.13837v1/x1.png"> |[Github](https://github.com/LeapLabTHU/limit-of-RLVR) <br> [Paper](https://arxiv.org/abs/2504.13837)| [//]: #04/22
| [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2022-blue)]()<br>[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) <br> Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou |<img width="1002" alt="image" src="figures/cot_prompting.png"> |[Paper](https://arxiv.org/abs/2201.11903)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/princeton-nlp/tree-of-thought-llm.svg?style=social&label=Star)](https://github.com/princeton-nlp/tree-of-thought-llm) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2023-blue)]()<br>[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) <br> Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan |<img width="1002" alt="image" src="https://arxiv.org/html/2305.10601v2/x1.png"> |[Github](https://github.com/princeton-nlp/tree-of-thought-llm) <br> [Paper](https://arxiv.org/abs/2305.10601)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/spcl/graph-of-thoughts.svg?style=social&label=Star)](https://github.com/spcl/graph-of-thoughts) [![Publish](https://img.shields.io/badge/Conference-AAAI_2024-blue)]()<br>[Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/abs/2308.09687) <br> Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler |<img width="1002" alt="image" src="figures/got.png"> |[Github](https://github.com/spcl/graph-of-thoughts) <br> [Paper](https://arxiv.org/abs/2308.09687)| [//]: #04/08
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2023-blue)]()<br>[Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171) <br> Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou |<img width="1002" alt="image" src="figures/sc.png"> |[Paper](https://arxiv.org/abs/2203.11171)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/TIGER-AI-Lab/Program-of-Thoughts.svg?style=social&label=Star)](https://github.com/TIGER-AI-Lab/Program-of-Thoughts) [![Publish](https://img.shields.io/badge/Conference-TMLR_2023-blue)]()<br>[Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/abs/2211.12588) <br> Wenhu Chen, Xueguang Ma, Xinyi Wang, William W. Cohen |<img width="1002" alt="image" src="figures/pot.png"> |[Github](https://github.com/TIGER-AI-Lab/Program-of-Thoughts) <br> [Paper](https://arxiv.org/abs/2211.12588)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/hanxuhu/chain-of-symbol-planning.svg?style=social&label=Star)](https://github.com/hanxuhu/chain-of-symbol-planning) [![Publish](https://img.shields.io/badge/Conference-COLM_2024-blue)]()<br>[Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models](https://arxiv.org/abs/2305.10276) <br> Hanxu Hu, Hongyuan Lu, Huajian Zhang, Yun-Ze Song, Wai Lam, Yue Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2305.10276v7/x1.png"> |[Github](https://github.com/hanxuhu/chain-of-symbol-planning) <br> [Paper](https://arxiv.org/abs/2305.10276)| [//]: #04/08

###### Survey
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Thinking Machines: A Survey of LLM based Reasoning Strategies](https://arxiv.org/abs/2503.10814) <br> Dibyanayan Bandyopadhyay, Soham Bhattacharjee, Asif Ekbal |<img width="1002" alt="image" src="https://arxiv.org/html/2503.10814v1/x1.png"> |[Paper](https://arxiv.org/abs/2503.10814)| [//]: #04/08
|[![Star](https://img.shields.io/github/stars/zzli2022/Awesome-System2-Reasoning-LLM.svg?style=social&label=Star)](https://github.com/zzli2022/Awesome-System2-Reasoning-LLM)<br>[From System 1 to System 2: A Survey of Reasoning Large Language Models](https://arxiv.org/abs/2502.17419) <br> Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhijiang Guo, Le Song, Cheng-Lin Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2502.17419v2/extracted/6232702/images/timeline.png"> |[Github](https://github.com/zzli2022/Awesome-System2-Reasoning-LLM) <br> [Paper](https://arxiv.org/abs/2502.17419)| [//]: #04/08


### Competition

*  [![Publish](https://img.shields.io/badge/Competition-AIMO_2-yellow)]() [![Star](https://img.shields.io/github/stars/NVIDIA/NeMo-Skills.svg?style=social&label=Star)](https://github.com/NVIDIA/NeMo-Skills) [AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset](https://arxiv.org/abs/2504.16891). Ivan Moshkov, Darragh Hanley, Ivan Sorokin, Shubham Toshniwal, Christof Henkel, Benedikt Schifferer, Wei Du, Igor Gitman. [[Paper]](https://arxiv.org/abs/2504.16891)[[Github]](https://github.com/NVIDIA/NeMo-Skills)


## Acknowledgement

This repository is inspired by [Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM/)


## Citation

```bibtex
@article{,
    title={Efficient Reasoning Models: A Survey},
    author={Feng, Sicheng and Fang, Gongfan and Ma, Xinyin and Wang, Xinchao},
    journal={arXiv preprint arXiv:2504.10903},
    year={2025},
}
```
